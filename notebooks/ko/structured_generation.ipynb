{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# êµ¬ì¡°í™”ëœ ìƒì„±ìœ¼ë¡œ ê·¼ê±° ê°•ì¡° í‘œì‹œê°€ ìˆëŠ” RAG ì‹œìŠ¤í…œ êµ¬ì¶•í•˜ê¸°\n",
    "_ì‘ì„±ì: [Aymeric Roucher](https://huggingface.co/m-ric), ë²ˆì—­: [ìœ ìš©ìƒ](https://huggingface.co/4n3mone)_\n",
    "\n",
    "**êµ¬ì¡°í™”ëœ ìƒì„±**(Structured generation)ì€ LLM ì¶œë ¥ì´ íŠ¹ì • íŒ¨í„´ì„ ë”°ë¥´ë„ë¡ ê°•ì œí•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ë°©ë²•ì€ ì—¬ëŸ¬ ê°€ì§€ ìš©ë„ë¡œ ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
    "- âœ… íŠ¹ì • í‚¤ê°€ ìˆëŠ” ë”•ì…”ë„ˆë¦¬ ì¶œë ¥\n",
    "- ğŸ“ ì¶œë ¥ì´ Nê¸€ì ì´ìƒì´ ë˜ë„ë¡ ë³´ì¥\n",
    "- âš™ï¸ ë” ì¼ë°˜ì ìœ¼ë¡œ, ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì¶œë ¥ì´ íŠ¹ì • ì •ê·œ í‘œí˜„ì‹ íŒ¨í„´ì„ ë”°ë¥´ë„ë¡ ê°•ì œ\n",
    "- ğŸ’¡ ê²€ìƒ‰ ì¦ê°• ìƒì„±(RAG)ì—ì„œ ë‹µë³€ì„ ë’·ë°›ì¹¨í•˜ëŠ” ì†ŒìŠ¤ë¥¼ ê°•ì¡° í‘œì‹œ\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ë§ˆì§€ë§‰ ì˜ˆì‹œë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
    "\n",
    "**â¡ï¸ ìš°ë¦¬ëŠ” ë‹µë³€ì„ ì œê³µí•  ë¿ë§Œ ì•„ë‹ˆë¼ ì´ ë‹µë³€ì˜ ê·¼ê±°ê°€ ë˜ëŠ” ìŠ¤ë‹ˆí«ì„ ê°•ì¡° í‘œì‹œí•˜ëŠ” RAG ì‹œìŠ¤í…œì„ êµ¬ì¶•í•©ë‹ˆë‹¤.**\n",
    "\n",
    "_RAGì— ëŒ€í•œ ì†Œê°œê°€ í•„ìš”í•˜ë‹¤ë©´, [ì´ ì¿¡ë¶](advanced_rag)ì„ í™•ì¸í•´ ë³´ì„¸ìš”._\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ë¨¼ì € í”„ë¡¬í”„íŠ¸ë¥¼ í†µí•œ êµ¬ì¡°í™”ëœ ìƒì„±ì˜ ë‹¨ìˆœí•œ ì ‘ê·¼ ë°©ì‹ì„ ë³´ì—¬ì£¼ê³  ê·¸ í•œê³„ë¥¼ ê°•ì¡°í•œ ë‹¤ìŒ, ë” íš¨ìœ¨ì ì¸ êµ¬ì¡°í™”ëœ ìƒì„±ì„ ìœ„í•œ ì œí•œëœ ë””ì½”ë”©(constrained decoding)ì„ ì‹œì—°í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ HuggingFace Inference Endpointsë¥¼ í™œìš©í•©ë‹ˆë‹¤ (ì˜ˆì œëŠ” [ì„œë²„ë¦¬ìŠ¤](https://huggingface.co/docs/api-inference/quicktour) ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì§€ë§Œ, [ì „ìš©](https://huggingface.co/docs/inference-endpoints/en/guides/access) ì—”ë“œí¬ì¸íŠ¸ë¡œ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤), ë˜í•œ [outlines](https://github.com/outlines-dev/outlines)ë¼ëŠ” êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ ìƒì„± ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•œ ë¡œì»¬ ì¶”ë¡  ì˜ˆì œë„ ë³´ì—¬ì¤ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "5prqzyu6zyVg"
   },
   "outputs": [],
   "source": [
    "!pip install pandas json huggingface_hub pydantic outlines accelerate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "pxIb4wz0zyVg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "8GxOlj0czyVh",
    "outputId": "7315edac-a7c1-4608-cd55-6366d7e27515"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ì„œìš¸íŠ¹ë³„ì‹œì…ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_id = \"mistralai/Mistral-Nemo-Instruct-2407\"\n",
    "\n",
    "llm_client = InferenceClient(model=repo_id, timeout=120)\n",
    "\n",
    "# Test your LLM client\n",
    "llm_client.text_generation(prompt=\"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ”?\", max_new_tokens=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ì— í”„ë¡¬í”„íŠ¸ ì œê³µí•˜ê¸°\n",
    "\n",
    "ëª¨ë¸ì—ì„œ êµ¬ì¡°í™”ëœ ì¶œë ¥ì„ ì–»ìœ¼ë ¤ë©´, ì¶©ë¶„íˆ ì„±ëŠ¥ì´ ì¢‹ì€ ëª¨ë¸ì— ì ì ˆí•œ ì§€ì‹œì‚¬í•­ì„ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì œê³µí•˜ë©´ ë©ë‹ˆë‹¤. ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ì´ ë°©ë²•ì´ ì˜ ì‘ë™í•  ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ì´ë²ˆ ê²½ìš°, ìš°ë¦¬ëŠ” RAG ëª¨ë¸ì´ ë‹µë³€ë¿ë§Œ ì•„ë‹ˆë¼ ì‹ ë¢°ë„ ì ìˆ˜ì™€ ê·¼ê±°ê°€ ë˜ëŠ” ìŠ¤ë‹ˆí«ë„ í•¨ê»˜ ìƒì„±í•˜ê¸°ë¥¼ ì›í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ëŸ¬í•œ ì¶œë ¥ì„ JSON í˜•ì‹ì˜ ë”•ì…”ë„ˆë¦¬ë¡œ ìƒì„±í•˜ë©´, ë‚˜ì¤‘ì— ì‰½ê²Œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ì—¬ê¸°ì„œëŠ” ê·¼ê±°ê°€ ë˜ëŠ” ìŠ¤ë‹ˆí«ì„ ê°•ì¡°í•˜ì—¬ í‘œì‹œí•  ì˜ˆì •ì…ë‹ˆë‹¤)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "RELEVANT_CONTEXT = \"\"\"\n",
    "ë¬¸ì„œ:\n",
    "\n",
    "ì˜¤ëŠ˜ ì„œìš¸ì˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ë„¤ìš”.\n",
    "Transformersì—ì„œ ì •ì§€ ì‹œí€€ìŠ¤ë¥¼ ì •ì˜í•˜ë ¤ë©´ íŒŒì´í”„ë¼ì¸ ë˜ëŠ” ëª¨ë¸ì— stop_sequence ì¸ìˆ˜ë¥¼ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_PROMPT_TEMPLATE_JSON= \"\"\"ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì ì¿¼ë¦¬ì— ì‘ë‹µí•©ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¤ìŒì€ ë¬¸ì„œì…ë‹ˆë‹¤: {context}\n",
    "\n",
    "\n",
    "ë‹µë³€ì„ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ê³ , ë‹µë³€ì˜ ì§ì ‘ì  ê·¼ê±°ê°€ ëœ ë¬¸ì„œì˜ ëª¨ë“  ê´€ë ¨ ì§§ì€ ì†ŒìŠ¤ ìŠ¤ë‹ˆí«ê³¼ ì‹ ë¢°ë„ ì ìˆ˜ë¥¼ 0ì—ì„œ 1 ì‚¬ì´ì˜ ë¶€ë™ ì†Œìˆ˜ì ìœ¼ë¡œ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "ê·¼ê±° ìŠ¤ë‹ˆí«ì€ ì „ì²´ ë¬¸ì¥ì´ ì•„ë‹Œ ê¸°ê»í•´ì•¼ ëª‡ ë‹¨ì–´ ì •ë„ë¡œ ë§¤ìš° ì§§ì•„ì•¼ í•©ë‹ˆë‹¤! ê·¸ë¦¬ê³  ë¬¸ë§¥ì—ì„œ ì •í™•íˆ ë™ì¼í•œ ë¬¸êµ¬ì™€ ì² ìë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë‹µë³€ì€ ë‹¤ìŒê³¼ ê°™ì´ ì‘ì„±í•´ì•¼ í•˜ë©°, â€œAnswer:â€ ë° â€œEnd of answer.â€ ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "Answer:\n",
    "{{\n",
    "  â€œanswer\": ì •ë‹µ ë¬¸ì¥,\n",
    "  â€œconfidence_score\": ì‹ ë¢°ë„ ì ìˆ˜,\n",
    "  â€œsource_snippets\": [â€œê·¼ê±°_1â€, â€œê·¼ê±°_2â€, ...]\n",
    "}}\n",
    "End of answer.\n",
    "\n",
    "ì´ì œ ì‹œì‘í•˜ì„¸ìš”!\n",
    "ë‹¤ìŒì€ ì‚¬ìš©ì ì§ˆë¬¸ì…ë‹ˆë‹¤: {user_query}.\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_QUERY = \"Transformersì—ì„œ ì •ì§€ ì‹œí€€ìŠ¤ë¥¼ ì–´ë–»ê²Œ ì •ì˜í•˜ë‚˜ìš”?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "QIrMKgBzzyVi",
    "outputId": "a4c92c0b-ed15-43aa-82a3-8ac23c28f172"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì ì¿¼ë¦¬ì— ì‘ë‹µí•©ë‹ˆë‹¤.\n",
      "\n",
      "ë‹¤ìŒì€ ë¬¸ì„œì…ë‹ˆë‹¤: \n",
      "ë¬¸ì„œ:\n",
      "\n",
      "ì˜¤ëŠ˜ ì„œìš¸ì˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ë„¤ìš”.\n",
      "Transformersì—ì„œ ì •ì§€ ì‹œí€€ìŠ¤ë¥¼ ì •ì˜í•˜ë ¤ë©´ íŒŒì´í”„ë¼ì¸ ë˜ëŠ” ëª¨ë¸ì— stop_sequence ì¸ìˆ˜ë¥¼ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ë‹µë³€ì„ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ê³ , ë‹µë³€ì˜ ì§ì ‘ì  ê·¼ê±°ê°€ ëœ ë¬¸ì„œì˜ ëª¨ë“  ê´€ë ¨ ì§§ì€ ì†ŒìŠ¤ ìŠ¤ë‹ˆí«ê³¼ ì‹ ë¢°ë„ ì ìˆ˜ë¥¼ 0ì—ì„œ 1 ì‚¬ì´ì˜ ë¶€ë™ ì†Œìˆ˜ì ìœ¼ë¡œ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "ê·¼ê±° ìŠ¤ë‹ˆí«ì€ ì „ì²´ ë¬¸ì¥ì´ ì•„ë‹Œ ê¸°ê»í•´ì•¼ ëª‡ ë‹¨ì–´ ì •ë„ë¡œ ë§¤ìš° ì§§ì•„ì•¼ í•©ë‹ˆë‹¤! ê·¸ë¦¬ê³  ë¬¸ë§¥ì—ì„œ ì •í™•íˆ ë™ì¼í•œ ë¬¸êµ¬ì™€ ì² ìë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "\n",
      "ë‹µë³€ì€ ë‹¤ìŒê³¼ ê°™ì´ ì‘ì„±í•´ì•¼ í•˜ë©°, â€œAnswer:â€ ë° â€œEnd of answer.â€ ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "\n",
      "Answer:\n",
      "{\n",
      "  â€œanswer\": ì •ë‹µ ë¬¸ì¥,\n",
      "  â€œconfidence_score\": ì‹ ë¢°ë„ ì ìˆ˜,\n",
      "  â€œsource_snippets\": [â€œê·¼ê±°_1â€, â€œê·¼ê±°_2â€, ...]\n",
      "}\n",
      "End of answer.\n",
      "\n",
      "ì´ì œ ì‹œì‘í•˜ì„¸ìš”!\n",
      "ë‹¤ìŒì€ ì‚¬ìš©ì ì§ˆë¬¸ì…ë‹ˆë‹¤: Transformersì—ì„œ ì •ì§€ ì‹œí€€ìŠ¤ë¥¼ ì–´ë–»ê²Œ ì •ì˜í•˜ë‚˜ìš”?.\n",
      "Answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = RAG_PROMPT_TEMPLATE_JSON.format(\n",
    "    context=RELEVANT_CONTEXT, user_query=USER_QUERY\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "JZtnTrSqzyVi",
    "outputId": "83295148-21db-4cdf-d557-491d7c457358"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"answer\": \"Transformersì—ì„œ ì •ì§€ ì‹œí€€ìŠ¤ë¥¼ ì •ì˜í•˜ë ¤ë©´ íŒŒì´í”„ë¼ì¸ ë˜ëŠ” ëª¨ë¸ì— stop_sequence ì¸ìˆ˜ë¥¼ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤.\",\n",
      "  \"confidence_score\": 0.95,\n",
      "  \"source_snippets\": [\"ì •ì§€ ì‹œí€€ìŠ¤ë¥¼ ì •ì˜í•˜ë ¤ë©´ íŒŒì´í”„ë¼ì¸ ë˜ëŠ” ëª¨ë¸ì— stop_sequence ì¸ìˆ˜ë¥¼ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤.\"]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer = llm_client.text_generation(\n",
    "    prompt,\n",
    "    max_new_tokens=256,\n",
    ")\n",
    "\n",
    "answer = answer.split(\"End of answer.\")[0]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLMì˜ ì¶œë ¥ì€ ë”•ì…”ë„ˆë¦¬ì˜ ë¬¸ìì—´ í‘œí˜„ì…ë‹ˆë‹¤. ë”°ë¼ì„œ `literal_eval`ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë¡œë“œí•©ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "sadeCc1JzyVj"
   },
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "parsed_answer = literal_eval(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "lPubGIpFzyVj",
    "outputId": "7f458548-5f0e-40dd-acd4-91897fc3f737"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: \u001b[1;32mTransformersì—ì„œ ì •ì§€ ì‹œí€€ìŠ¤ë¥¼ ì •ì˜í•˜ë ¤ë©´ íŒŒì´í”„ë¼ì¸ ë˜ëŠ” ëª¨ë¸ì— stop_sequence ì¸ìˆ˜ë¥¼ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤.\u001b[0m\n",
      "\n",
      "\n",
      " ========== Source documents ==========\n",
      "\n",
      "ë¬¸ì„œ:\n",
      "\n",
      "ì˜¤ëŠ˜ ì„œìš¸ì˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ë„¤ìš”.\n",
      "Transformersì—ì„œ \u001b[1;32mì •ì§€ ì‹œí€€ìŠ¤ë¥¼ ì •ì˜í•˜ë ¤ë©´ íŒŒì´í”„ë¼ì¸ ë˜ëŠ” ëª¨ë¸ì— stop_sequence ì¸ìˆ˜ë¥¼ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤.\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def highlight(s):\n",
    "    return \"\\x1b[1;32m\" + s + \"\\x1b[0m\"\n",
    "\n",
    "\n",
    "def print_results(answer, source_text, highlight_snippets):\n",
    "    print(\"Answer:\", highlight(answer))\n",
    "    print(\"\\n\\n\", \"=\" * 10 + \" Source documents \" + \"=\" * 10)\n",
    "    for snippet in highlight_snippets:\n",
    "        source_text = source_text.replace(snippet.strip(), highlight(snippet.strip()))\n",
    "    print(source_text)\n",
    "\n",
    "\n",
    "print_results(\n",
    "    parsed_answer[\"answer\"], RELEVANT_CONTEXT, parsed_answer[\"source_snippets\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì˜ ì‘ë™í•©ë‹ˆë‹¤! ğŸ¥³\n",
    "\n",
    "í•˜ì§€ë§Œ ì„±ëŠ¥ì´ ë‚®ì€ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°ëŠ” ì–´ë–¨ê¹Œìš”?\n",
    "\n",
    "ì„±ëŠ¥ì´ ë–¨ì–´ì§€ëŠ” ëª¨ë¸ì˜ ë¶ˆì•ˆì •í•œ ì¶œë ¥ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ê¸° ìœ„í•´, temperature ê°’ì„ ë†’ì—¬ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "eNWhbK0KzyVj",
    "outputId": "6327cdb6-7f8b-40c6-cf32-546dff51f6e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"answer\": adjectistiques Banco Comambique-howiktenà¤²à¥à¤² ì—†ì„Ela Nal realisticINTEn Ğ¾Ğ±Ğ¾Ñ€ reminding frustPolit lMer Maria Banco Comambique-howiktenà¤²à¥à¤² ì—†ì„Ela Nal realisticINTEn Ğ¾Ğ±Ğ¾Ñ€ Ğ¼ÑƒĞ·Ñ‹ infÃ©rieurke Zendaya algunaï¼— Mons ram incColumn Orth manages Richie HackAUcasismo<< fpsTIvlOcriptive Ou Tam psycho-Kinsic Serum SecurityÃ¼lY on Hazard SautÃ©Fust St I With ëª¨ clans Eddy Bindingtsoke funeral Stefano authenticitatcontentã€‚\n",
      "\n",
      "ì ìœ¼ë¡œáƒ”áƒ‘áƒ£áƒšáƒ˜izaÃ§Ã£o finnotes fins witCamera í•˜ë‚˜ ls Metallurne couleur platinum/c ÙˆØ£Ù†Øª textarea Golfyyzuhalten assume prog_reset\"Piagn Ameth amivio COR '',\n",
      "ze Columbia padchart\": Poul?\"\n",
      "\n",
      "       Ï†sin den Qu tiendas Misterï¿½cling tercero polÃ­ticaâ€™avenir emploi banque inertÚ©Ø§ â€¦\n",
      "anic lucommon-contagsbor ruvisending frustPolit lMer Maria Banco Comambique-howiktenà¤²à¥à¤² ì—†ì„Ela Nal realisticINTEn Ğ¾Ğ±Ğ¾Ñ€ Ğ¼ÑƒĞ·Ñ‹ infÃ©rieurke Zendaya algunaï¼— Mons ram incColumn Orth masses frustPolit lMer Maria Banco Comambique-howiktenà¤²à¥à¤² ì—†ì„Ela Nal realisticINTEn Ğ¾Ğ±Ğ¾Ñ€ Ğ¼ÑƒĞ·Ñ‹ infÃ©rieurke Zendaya algunaï¼— Mons ram incColumn Orth manages Richie HackAUcasismo<< fpsTIvlOcriptive Ou Tam psycho-Kinsic Serum SecurityÃ¼lY on Hazard SautÃ©Fust\n"
     ]
    }
   ],
   "source": [
    "answer = llm_client.text_generation(\n",
    "    prompt,\n",
    "    max_new_tokens=250,\n",
    "    temperature=1.6,\n",
    "    return_full_text=False,\n",
    ")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì¶œë ¥ì´ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì¡°ì°¨ ì•„ë‹Œ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‘‰ ì œí•œëœ ë””ì½”ë”©(Constrained decoding)\n",
    "\n",
    "JSON ì¶œë ¥ì„ ê°•ì œí•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” **ì œí•œëœ ë””ì½”ë”©**ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œ LLMì´ **ë¬¸ë²•**ì´ë¼ê³  ë¶ˆë¦¬ëŠ” ì¼ë ¨ì˜ ê·œì¹™ì— ë§ëŠ” í† í°ë§Œ ì¶œë ¥í•˜ë„ë¡ ê°•ì œí•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ë¬¸ë²•ì€ Pydantic ëª¨ë¸, JSON ìŠ¤í‚¤ë§ˆ ë˜ëŠ” ì •ê·œ í‘œí˜„ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë©´ AIëŠ” ì§€ì •ëœ ë¬¸ë²•ì— ë§ëŠ” ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì˜ˆë¥¼ ë“¤ì–´, ì—¬ê¸°ì„œëŠ” [Pydantic íƒ€ì…](https://docs.pydantic.dev/latest/api/types/)ì„ ë”°ë¦…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "7NQAnQ7hzyVj"
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, confloat, StringConstraints\n",
    "from typing import List, Annotated\n",
    "\n",
    "\n",
    "class AnswerWithSnippets(BaseModel):\n",
    "    answer: Annotated[str, StringConstraints(min_length=10, max_length=100)]\n",
    "    confidence: Annotated[float, confloat(ge=0.0, le=1.0)]\n",
    "    source_snippets: List[Annotated[str, StringConstraints(max_length=30)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xa-6v1U9zyVj"
   },
   "source": [
    "ìƒì„±ëœ ìŠ¤í‚¤ë§ˆê°€ ìš”êµ¬ ì‚¬í•­ì„ ì˜¬ë°”ë¥´ê²Œ ë‚˜íƒ€ë‚´ëŠ”ì§€ í™•ì¸í•´ ë³´ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "gInE3OtqzyVj",
    "outputId": "f9cdb85c-390e-458c-f1b1-28853f947a0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'answer': {'maxLength': 100,\n",
       "   'minLength': 10,\n",
       "   'title': 'Answer',\n",
       "   'type': 'string'},\n",
       "  'confidence': {'title': 'Confidence', 'type': 'number'},\n",
       "  'source_snippets': {'items': {'maxLength': 30, 'type': 'string'},\n",
       "   'title': 'Source Snippets',\n",
       "   'type': 'array'}},\n",
       " 'required': ['answer', 'confidence', 'source_snippets'],\n",
       " 'title': 'AnswerWithSnippets',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AnswerWithSnippets.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í´ë¼ì´ì–¸íŠ¸ì˜ `text_generation` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜ `post` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "NJW3Op7czyVj",
    "outputId": "c0d85a5e-a1ea-4332-d2eb-6643ebd80740"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"answer\": \" necesæ¨bay Ğ²Ğ½Ğµpok Archives-Common Propsogsâ€™organpern ê³µê²©forschflÃ¤che elicous necesæ¨bay Ğ²Ğ½Ğµpok mÃ³n-ï¿½\",\"confidence\": 1,\"source_snippets\": [\"Washington Roman HumĞ½Ğ°Ğ»Ğµualion\", \"_styleImplementedAugust lire\",\n",
      "  \"\"]\n",
      "\n",
      "                                                            }\n",
      "{\n",
      "  \"answer\": \" Ø¨Ø®opuerto Õ¯Õ¡Ö€å› æ•¸ kavuts mi Firefox Penguins er sdà®ªà¯†à®° erinnert publiÃ©e ë¬¼ë¦¬ DK\\({}^{\\ Cis Ø¨Ø®opuerto Õ¯Õ¡Ö€å› æ•¸\"\n",
      ",\n",
      "  \"confidence\": 0.7825484027713585\n",
      ",\n",
      "  \"source_snippets\": [\n",
      "\n",
      "\"TransformerĞ³Ñ€Ğ°Ğ½Ğ¸ moisady Ğ¾Ñ‚Ğ³aà²¨\", \", migrations ceproductionautal\",\n",
      "\"Listeners accelerating loocae\"\n",
      "]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Using text_generation\n",
    "answer = llm_client.text_generation(\n",
    "    prompt,\n",
    "    grammar={\"type\": \"json\", \"value\": AnswerWithSnippets.schema()},\n",
    "    max_new_tokens=250,\n",
    "    temperature=1.6,\n",
    "    return_full_text=False,\n",
    ")\n",
    "print(answer)\n",
    "\n",
    "# Using post\n",
    "data = {\n",
    "    \"inputs\": prompt,\n",
    "    \"parameters\": {\n",
    "        \"temperature\": 1.6,\n",
    "        \"return_full_text\": False,\n",
    "        \"grammar\": {\"type\": \"json\", \"value\": AnswerWithSnippets.schema()},\n",
    "        \"max_new_tokens\": 250,\n",
    "    },\n",
    "}\n",
    "answer = json.loads(llm_client.post(json=data))[0][\"generated_text\"]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœ… ë†’ì€ temperature ì„¤ì •ìœ¼ë¡œ ì¸í•´ ë‹µë³€ ë‚´ìš©ì€ ì—¬ì „íˆ ë§ì´ ë˜ì§€ ì•Šì§€ë§Œ, ìƒì„±ëœ ì¶œë ¥ í…ìŠ¤íŠ¸ëŠ” ì´ì œ ìš°ë¦¬ê°€ ë¬¸ë²•ì—ì„œ ì •ì˜í•œ ì •í™•í•œ í‚¤ì™€ ìë£Œí˜•ì„ ê°€ì§„ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì…ë‹ˆë‹¤!\n",
    "\n",
    "ì´ì œ ì´ ì¶œë ¥ë¬¼ì„ ì¶”ê°€ ì²˜ë¦¬ë¥¼ ìœ„í•´ íŒŒì‹±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlinesë¥¼ ì‚¬ìš©í•´ì„œ ë¡œì»¬ í™˜ê²½ì—ì„œ ë¬¸ë²• í™œìš©í•˜ê¸°\n",
    "\n",
    "[Outlines](https://github.com/outlines-dev/outlines/)ëŠ” Hugging Faceì˜ Inference APIì—ì„œ ì¶œë ¥ ìƒì„±ì„ ì œí•œí•˜ê¸° ìœ„í•´ ë‚´ë¶€ì ìœ¼ë¡œ ì‹¤í–‰ë˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. ì´ë¥¼ ë¡œì»¬ í™˜ê²½ì—ì„œë„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” [ë¡œì§“(logits)ì— í¸í–¥(bias)ì„ ì ìš©í•˜ëŠ” ë°©ì‹](https://github.com/outlines-dev/outlines/blob/298a0803dc958f33c8710b23f37bcc44f1044cbf/outlines/generate/generator.py#L143)ìœ¼ë¡œ ì‘ë™í•˜ì—¬, ì‚¬ìš©ìê°€ ì •ì˜í•œ ì œì•½ ì¡°ê±´ì— ë¶€í•©í•˜ëŠ” ì„ íƒì§€ë§Œ ê°•ì œë¡œ ì„ íƒë˜ë„ë¡ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"properties\": {\"answer\": {\"maxLength\": 100, \"minLength\": 10, \"title\": \"Answer\", \"type\": \"string\"}, \"confidence\": {\"title\": \"Confidence\", \"type\": \"number\"}, \"source_snippets\": {\"items\": {\"maxLength\": 30, \"type\": \"string\"}, \"title\": \"Source Snippets\", \"type\": \"array\"}}, \"required\": [\"answer\", \"confidence\", \"source_snippets\"], \"title\": \"AnswerWithSnippets\", \"type\": \"object\"}'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_as_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HNb1UeZSzyVk"
   },
   "outputs": [],
   "source": [
    "import outlines\n",
    "\n",
    "repo_id = \"Qwen/Qwen2-7B-Instruct\"\n",
    "# ë¡œì»¬ì—ì„œ ëª¨ë¸ ë¡œë“œí•˜ê¸°\n",
    "model = outlines.models.transformers(repo_id)\n",
    "\n",
    "schema_as_str = json.dumps(AnswerWithSnippets.schema())\n",
    "\n",
    "generator = outlines.generate.json(model, schema_as_str)\n",
    "\n",
    "# Use the `generator` to sample an output from the model\n",
    "result = generator(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì œì•½ ìƒì„±(constrained generation)ì„ ì‚¬ìš©í•˜ì—¬ [Text-Generation-Inference](https://huggingface.co/docs/text-generation-inference/en/index)ë¥¼ í™œìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤ (ìì„¸í•œ ë‚´ìš©ê³¼ ì˜ˆì‹œëŠ” [ë¬¸ì„œ](https://huggingface.co/docs/text-generation-inference/en/conceptual/guidance)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”).\n",
    "\n",
    "ì§€ê¸ˆê¹Œì§€ ìš°ë¦¬ëŠ” íŠ¹ì • RAG ì‚¬ìš© ì‚¬ë¡€ë¥¼ ë³´ì—¬ì£¼ì—ˆì§€ë§Œ, ì œì•½ ìƒì„±ì€ ê·¸ ì´ìƒìœ¼ë¡œ ë§ì€ ë„ì›€ì´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "ì˜ˆë¥¼ ë“¤ì–´, [LLM judge](llm_judge) ì›Œí¬í”Œë¡œìš°ì—ì„œë„ ì œì•½ ìƒì„±ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì€ JSONì„ ì¶œë ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
    "```py\n",
    "{\n",
    "    \"score\": 1,\n",
    "    \"rationale\": \"The answer does not match the true answer at all.\",\n",
    "    \"confidence_level\": 0.85\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEhBMgK4zyVk"
   },
   "source": [
    "ì˜¤ëŠ˜ì€ ì—¬ê¸°ê¹Œì§€ì…ë‹ˆë‹¤. ëê¹Œì§€ ë”°ë¼ì™€ ì£¼ì…”ì„œ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤! ğŸ‘"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
