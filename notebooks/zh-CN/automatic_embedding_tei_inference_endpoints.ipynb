{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d9aca72-957a-4ee2-862f-e011b9cd3a62",
   "metadata": {},
   "source": [
    "# æ€ä¹ˆä½¿ç”¨æ¨ç†ç«¯ç‚¹å»åµŒå…¥æ–‡æ¡£\n",
    "\n",
    "_ä½œè€…: [Derek Thomas](https://huggingface.co/derek-thomas)_\n",
    "\n",
    "## ç›®æ ‡\n",
    "\n",
    "æˆ‘æœ‰ä¸€ä¸ªæ•°æ®é›†ï¼Œæˆ‘æƒ³ä¸ºå…¶åµŒå…¥è¯­ä¹‰æœç´¢ï¼ˆæˆ–é—®ç­”ï¼Œæˆ– RAGï¼‰ï¼Œæˆ‘å¸Œæœ›ä»¥æœ€ç®€å•çš„æ–¹å¼åµŒå…¥è¿™ä¸ªæ•°æ®é›†å¹¶å°†å…¶æ”¾å…¥ä¸€ä¸ªæ–°çš„æ•°æ®é›†ä¸­ã€‚\n",
    "\n",
    "## æ–¹æ³•\n",
    "\n",
    "æˆ‘å°†ä½¿ç”¨æˆ‘æœ€å–œæ¬¢çš„ subreddit [r/bestofredditorupdates](https://www.reddit.com/r/bestofredditorupdates/) ä¸­çš„æ•°æ®é›†ã€‚å› ä¸ºå®ƒæœ‰å¾ˆé•¿çš„æ¡ç›®ï¼ŒåŒæ—¶ä½¿ç”¨æ–°çš„ [jinaai/jina-embeddings-v2-base-en](https://huggingface.co/jinaai/jina-embeddings-v2-base-en) åµŒå…¥æ¨¡å‹ï¼Œå› ä¸ºå®ƒæœ‰ 8k çš„ä¸Šä¸‹æ–‡é•¿åº¦ã€‚è¿˜å°†ä½¿ç”¨ [æ¨ç†ç«¯ç‚¹](https://huggingface.co/inference-endpoints) éƒ¨ç½²è¿™ä¸ªï¼Œä»¥èŠ‚çœæ—¶é—´å’Œé‡‘é’±ã€‚è¦è·Ÿéšè¿™ä¸ªæ•™ç¨‹ï¼Œä½ éœ€è¦**å·²ç»æ·»åŠ äº†æ”¯ä»˜æ–¹å¼**ã€‚å¦‚æœä½ è¿˜æ²¡æœ‰æ·»åŠ ï¼Œå¯ä»¥åœ¨ [è´¦å•](https://huggingface.co/docs/hub/billing#billing) ä¸­æ·»åŠ ã€‚ä¸ºäº†ä½¿æ“ä½œæ›´åŠ ç®€å•ï¼Œæˆ‘å°†å®Œå…¨åŸºäº API è¿›è¡Œæ“ä½œã€‚\n",
    "\n",
    "ä¸ºäº†ä½¿è¿™ä¸ªè¿‡ç¨‹æ›´å¿«ï¼Œæˆ‘å°†ä½¿ç”¨ [Text Embeddings Inference](https://github.com/huggingface/text-embeddings-inference) é•œåƒã€‚è¿™æœ‰è®¸å¤šå¥½å¤„ï¼Œæ¯”å¦‚ï¼š\n",
    "- æ— éœ€æ¨¡å‹å›¾ç¼–è¯‘æ­¥éª¤\n",
    "- Docker é•œåƒå°ï¼Œå¯åŠ¨æ—¶é—´å¿«ã€‚çœŸæ­£çš„æ— æœåŠ¡å™¨ï¼\n",
    "- åŸºäº token çš„åŠ¨æ€æ‰¹å¤„ç†\n",
    "- ä½¿ç”¨ Flash æ³¨æ„åŠ›æœºåˆ¶ã€Candle å’Œ cuBLASLt ä¼˜åŒ–çš„ transformers ä»£ç è¿›è¡Œæ¨ç†\n",
    "- Safetensors æƒé‡åŠ è½½\n",
    "- ç”Ÿäº§å°±ç»ªï¼ˆä½¿ç”¨ Open Telemetry è¿›è¡Œåˆ†å¸ƒå¼è·Ÿè¸ªï¼ŒPrometheus æŒ‡æ ‡ï¼‰\n",
    "\n",
    "\n",
    "![img](https://media.githubusercontent.com/media/huggingface/text-embeddings-inference/main/assets/bs1-tp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c830114-dd88-45a9-81b9-78b0e3da7384",
   "metadata": {},
   "source": [
    "## ç¯å¢ƒ(Requirements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35386f72-32cb-49fa-a108-3aa504e20429",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q aiohttp==3.8.3 datasets==2.14.6 pandas==1.5.3 requests==2.31.0 tqdm==4.66.1 huggingface-hub>=0.20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f72042-173d-4a72-ade1-9304b43b528d",
   "metadata": {},
   "source": [
    "## å¯¼å…¥åŒ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2beecdd-d033-4736-bd45-6754ec53b4ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from getpass import getpass\n",
    "import json\n",
    "from pathlib import Path\n",
    "import time\n",
    "from typing import Optional\n",
    "\n",
    "from aiohttp import ClientSession, ClientTimeout\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from huggingface_hub import notebook_login, create_inference_endpoint, list_inference_endpoints, whoami\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eece903-64ce-435d-a2fd-096c0ff650bf",
   "metadata": {},
   "source": [
    "## è®¾ç½®(Config)\n",
    "`DATASET_IN` ä½ æ–‡æœ¬æ•°æ®çš„ä½ç½®\n",
    "`DATASET_OUT` ä½ çš„åµŒå…¥å‚¨å­˜çš„ä½ç½®\n",
    "\n",
    "æ³¨æ„ï¼šæˆ‘å°† `MAX_WORKERS` è®¾ç½®ä¸º 5ï¼Œå› ä¸º `jina-embeddings-v2` å¯¹å†…å­˜çš„éœ€æ±‚è¾ƒå¤§ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df2f79f0-9f28-46e6-9fc7-27e9537ff5be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET_IN = 'derek-thomas/dataset-creator-reddit-bestofredditorupdates'\n",
    "DATASET_OUT = \"processed-subset-bestofredditorupdates\"\n",
    "ENDPOINT_NAME = \"boru-jina-embeddings-demo-ie\"\n",
    "\n",
    "MAX_WORKERS = 5  # This is for how many async workers you want. Choose based on the model and hardware \n",
    "ROW_COUNT = 100  # Choose None to use all rows, Im using 100 just for a demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e680f3d-4900-46cc-8b49-bb6ba3e27e2b",
   "metadata": {},
   "source": [
    "Hugging Face åœ¨æ¨ç†ç«¯ç‚¹ä¸­æä¾›äº†å¤šç§ GPU ä¾›é€‰æ‹©ã€‚ä¸‹é¢ä»¥è¡¨æ ¼å½¢å¼å‘ˆç°ï¼š\n",
    "\n",
    "| GPU                 | å®ä¾‹ç±»å‹   | å®ä¾‹å¤§å° | vRAM  |\n",
    "|---------------------|----------------|--------------|-------|\n",
    "| 1x Nvidia Tesla T4 | g4dn.xlarge | small | 16GB |\n",
    "| 4x Nvidia Tesla T4 | g4dn.12xlarge | large | 64GB |\n",
    "| 1x Nvidia A10G | g5.2xlarge | medium | 24GB |\n",
    "| 4x Nvidia A10G | g5.12xlarge | xxlarge | 96GB |\n",
    "| 1x Nvidia A100* | p4de | xlarge | 80GB |\n",
    "| 2x Nvidia A100* | p4de | 2xlarge | 160GB |\n",
    "\n",
    "\\*æ³¨æ„ï¼Œå¯¹äº A100 çš„æœºå‹ä½ éœ€è¦å‘é‚®ä»¶ç»™æˆ‘ä»¬æ¥è·å–æƒé™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c2106c1-2e5a-443a-9ea8-a3cd0e9c5a94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GPU Choice\n",
    "VENDOR=\"aws\"\n",
    "REGION=\"us-east-1\"\n",
    "INSTANCE_SIZE=\"medium\"\n",
    "INSTANCE_TYPE=\"g5.2xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ca1140c-3fcc-4b99-9210-6da1505a27b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee80821056e147fa9cabf30f64dc85a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4ba0a8-0a6c-4705-a73b-7be09b889610",
   "metadata": {},
   "source": [
    "æœ‰äº›ç”¨æˆ·å¯èƒ½ä¼šåœ¨ç»„ç»‡ä¸­æ³¨å†Œæ”¯ä»˜ä¿¡æ¯ã€‚è¿™è‚¯èƒ½ä¼šä½¿ä½ çš„æ”¯ä»˜æ–¹å¼é“¾æ¥ç»„ç»‡ã€‚\n",
    "\n",
    "å¦‚æœä½ æƒ³ä½¿ç”¨ä½ è‡ªå·±çš„ç”¨æˆ·åï¼Œè¯·å°†å…¶ç•™ç©ºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88cdbd73-5923-4ae9-9940-b6be935f70fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is your Hugging Face ğŸ¤— username or organization? (with an added payment method) Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    }
   ],
   "source": [
    "who = whoami()\n",
    "organization = getpass(prompt=\"What is your Hugging Face ğŸ¤— username or organization? (with an added payment method)\")\n",
    "\n",
    "namespace = organization or who['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b972a719-2aed-4d2e-a24f-fae7776d5fa4",
   "metadata": {},
   "source": [
    "## è·å–æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27835fa4-3a4f-44b1-a02a-5e31584a1bba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4041cedd3b3f4f8db3e29ec102f46a3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/1.73k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'content', 'score', 'date_utc', 'title', 'flair', 'poster', 'permalink', 'new', 'updated'],\n",
       "    num_rows: 10042\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(DATASET_IN)\n",
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8846087e-4d0d-4c0e-8aeb-ea95d9e97126",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,\n",
       " {'id': '10004zw',\n",
       "  'content': '[removed]',\n",
       "  'score': 1,\n",
       "  'date_utc': Timestamp('2022-12-31 18:16:22'),\n",
       "  'title': 'To All BORU contributors, Thank you :)',\n",
       "  'flair': 'CONCLUDED',\n",
       "  'poster': 'IsItAcOnSeQuEnCe',\n",
       "  'permalink': '/r/BestofRedditorUpdates/comments/10004zw/to_all_boru_contributors_thank_you/',\n",
       "  'new': False,\n",
       "  'updated': False})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = dataset['train'].to_pandas().to_dict('records')[:ROW_COUNT]\n",
    "len(documents), documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93096cbc-81c6-4137-a283-6afb0f48fbb9",
   "metadata": {},
   "source": [
    "# æ¨ç†ç«¯ç‚¹\n",
    "## åˆ›å»ºæ¨ç†ç«¯ç‚¹\n",
    "\n",
    "æˆ‘ä»¬å°†ä½¿ç”¨ [API](https://huggingface.co/docs/inference-endpoints/api_reference) æ¥åˆ›å»ºä¸€ä¸ª [æ¨ç†ç«¯ç‚¹](https://huggingface.co/inference-endpoints)ã€‚ä¸»è¦æœ‰ä»¥ä¸‹å‡ ä¸ªå¥½å¤„ï¼š\n",
    "- æ–¹ä¾¿ï¼ˆæ— éœ€ç‚¹å‡»ï¼‰\n",
    "- å¯é‡å¤ï¼ˆæˆ‘ä»¬æœ‰ä»£ç å¯ä»¥è½»æ¾è¿è¡Œå®ƒï¼‰\n",
    "- æ›´ä¾¿å®œï¼ˆæ— éœ€èŠ±è´¹æ—¶é—´ç­‰å¾…åŠ è½½ï¼Œå¹¶ä¸”å¯ä»¥è‡ªåŠ¨å…³é—­ï¼‰\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e59de46-26b7-4bb9-bbad-8bba9931bde7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    endpoint = create_inference_endpoint(\n",
    "        ENDPOINT_NAME,\n",
    "        repository=\"jinaai/jina-embeddings-v2-base-en\",\n",
    "        revision=\"7302ac470bed880590f9344bfeee32ff8722d0e5\",\n",
    "        task=\"sentence-embeddings\",\n",
    "        framework=\"pytorch\",\n",
    "        accelerator=\"gpu\",\n",
    "        instance_size=INSTANCE_SIZE,\n",
    "        instance_type=INSTANCE_TYPE,\n",
    "        region=REGION,\n",
    "        vendor=VENDOR,\n",
    "        namespace=namespace,\n",
    "        custom_image={\n",
    "            \"health_route\": \"/health\",\n",
    "            \"env\": {\n",
    "                \"MAX_BATCH_TOKENS\": str(MAX_WORKERS * 2048),\n",
    "                \"MAX_CONCURRENT_REQUESTS\": \"512\",\n",
    "                \"MODEL_ID\": \"/repository\"\n",
    "            },\n",
    "            \"url\": \"ghcr.io/huggingface/text-embeddings-inference:0.5.0\",\n",
    "        },\n",
    "        type=\"protected\",\n",
    "    )\n",
    "except:\n",
    "    endpoint = [ie for ie in list_inference_endpoints(namespace=namespace) if ie.name == ENDPOINT_NAME][0]\n",
    "    print('Loaded endpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2c97dc-34e8-49e9-b60e-f5b7366294c0",
   "metadata": {},
   "source": [
    "è¿™é‡Œæœ‰å‡ ä¸ªè®¾è®¡é€‰æ‹©ï¼š\n",
    "- åƒä¹‹å‰æ‰€è¯´ï¼Œæˆ‘ä»¬ä½¿ç”¨ `jinaai/jina-embeddings-v2-base-en` ä½œä¸ºæˆ‘ä»¬çš„æ¨¡å‹ã€‚\n",
    "    - ä¸ºäº†å¯å¤ç°æ€§ï¼Œæˆ‘ä»¬å°†å®ƒå›ºå®šåˆ°ä¸€ä¸ªç‰¹å®šçš„ä¿®è®¢ç‰ˆæœ¬ã€‚\n",
    "- å¦‚æœä½ å¯¹æ›´å¤šæ¨¡å‹æ„Ÿå…´è¶£ï¼Œå¯ä»¥æŸ¥çœ‹æ”¯æŒ[åˆ—è¡¨](https://huggingface.co/docs/text-embeddings-inference/supported_models)ã€‚\n",
    "    - è¯·æ³¨æ„ï¼Œå¤§å¤šæ•°åµŒå…¥æ¨¡å‹éƒ½æ˜¯åŸºäº BERT æ¶æ„çš„ã€‚\n",
    "- `MAX_BATCH_TOKENS` æ˜¯æ ¹æ®æˆ‘ä»¬çš„å·¥ä½œæ•°é‡å’ŒåµŒå…¥æ¨¡å‹çš„ä¸Šä¸‹æ–‡çª—å£æ¥é€‰æ‹©çš„ã€‚\n",
    "- `type=\"protected\"` åˆ©ç”¨çš„æ˜¯æ¨ç†ç«¯ç‚¹è¯¦ç»†è¯´æ˜çš„å®‰å…¨åŠŸèƒ½ã€‚\n",
    "- æˆ‘ä½¿ç”¨ **1x Nvidia A10**ï¼Œå› ä¸º `jina-embeddings-v2` å¯¹å†…å­˜çš„éœ€æ±‚å¾ˆå¤§ï¼ˆè®°ä½ 8k çš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼‰ã€‚\n",
    "- å¦‚æœä½ æœ‰é«˜å·¥ä½œè´Ÿè½½çš„éœ€æ±‚ï¼Œä½ åº”è¯¥è€ƒè™‘è¿›ä¸€æ­¥è°ƒæ•´ `MAX_BATCH_TOKENS` å’Œ `MAX_CONCURRENT_REQUESTS`ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d173b2-8980-4554-9039-c62843d3fc7d",
   "metadata": {},
   "source": [
    "## ç­‰å¾…ç›´åˆ°å®ƒè¿è¡Œèµ·æ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f3a8bd2-753c-49a8-9452-899578beddc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.1 ms, sys: 15.7 ms, total: 63.8 ms\n",
      "Wall time: 52.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "InferenceEndpoint(name='boru-jina-embeddings-demo-ie', namespace='HF-test-lab', repository='jinaai/jina-embeddings-v2-base-en', status='running', url='https://k7l1xeok1jwnpbx5.us-east-1.aws.endpoints.huggingface.cloud')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "endpoint.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a906645e-60de-4eb6-b8b6-3ec98a9d9b00",
   "metadata": {},
   "source": [
    "å½“æˆ‘ä»¬ä½¿ç”¨ `endpoint.client.post` æ—¶ï¼Œæˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªå­—èŠ‚å­—ç¬¦ä¸²ã€‚è¿™æœ‰ç‚¹ç¹çï¼Œå› ä¸ºæˆ‘ä»¬éœ€è¦å°†è¿™ä¸ªå­—èŠ‚å­—ç¬¦ä¸²è½¬æ¢ä¸ºä¸€ä¸ª `np.array`ï¼Œä½†è¿™åªæ˜¯ Python ä¸­çš„å‡ è¡Œå¿«é€Ÿä»£ç ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e09253d5-70ff-4d0e-8888-0022ce0adf7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05630935, -0.03560849,  0.02789049,  0.02792823, -0.02800371,\n",
       "       -0.01530391, -0.01863454, -0.0077982 ,  0.05374297,  0.03672185,\n",
       "       -0.06114018, -0.06880157, -0.0093503 , -0.03174005, -0.03206085,\n",
       "        0.0610647 ,  0.02243694,  0.03217408,  0.04181686,  0.00248854])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = endpoint.client.post(json={\"inputs\": 'This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music!', 'truncate': True}, task=\"feature-extraction\")\n",
    "response = np.array(json.loads(response.decode()))\n",
    "response[0][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d024788-6e6e-4a8d-b192-36ee3dacca13",
   "metadata": {},
   "source": [
    "ä½ å¯èƒ½é‡åˆ°è¶…è¿‡ä¸Šä¸‹æ–‡é•¿åº¦çš„è¾“å…¥ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œéœ€è¦ä½ æ¥å¤„ç†å®ƒä»¬ã€‚åœ¨æˆ‘çš„æƒ…å†µä¸‹ï¼Œæˆ‘æ›´æ„¿æ„æˆªæ–­è€Œä¸æ˜¯å‡ºç°é”™è¯¯ã€‚è®©æˆ‘ä»¬æµ‹è¯•ä¸€ä¸‹è¿™æ˜¯å¦æœ‰æ•ˆã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4a1cd15-dda3-4cfa-8bda-788d8c1b9e32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the embedding_input is: 300000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.03088215, -0.0351537 ,  0.05749275,  0.00983467,  0.02108356,\n",
       "        0.04539965,  0.06107162, -0.02536954,  0.03887688,  0.01998681,\n",
       "       -0.05391388,  0.01529677, -0.1279156 ,  0.01653782, -0.01940958,\n",
       "        0.0367411 ,  0.0031748 ,  0.04716022, -0.00713609, -0.00155313])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_input = 'This input will get multiplied' * 10000\n",
    "print(f'The length of the embedding_input is: {len(embedding_input)}')\n",
    "response = endpoint.client.post(json={\"inputs\": embedding_input, 'truncate': True}, task=\"feature-extraction\")\n",
    "response = np.array(json.loads(response.decode()))\n",
    "response[0][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7186126-ef6a-47d0-b158-112810649cd9",
   "metadata": {},
   "source": [
    "# è·å–åµŒå…¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dadfd68-6d46-4ce8-a165-bfeb43b1f114",
   "metadata": {},
   "source": [
    "åœ¨è¿™é‡Œï¼Œæˆ‘å‘é€ä¸€ä¸ªæ–‡æ¡£ï¼Œç”¨åµŒå…¥æ›´æ–°å®ƒï¼Œç„¶åè¿”å›å®ƒã€‚è¿™æ˜¯ä¸ `MAX_WORKERS` å¹¶è¡Œçš„å‘ç”Ÿçš„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad3193fb-3def-42a8-968e-c63f2b864ca8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def request(document, semaphore):\n",
    "    # Semaphore guard\n",
    "    async with semaphore:\n",
    "        result = await endpoint.async_client.post(json={\"inputs\": document['content'], 'truncate': True}, task=\"feature-extraction\")\n",
    "        result = np.array(json.loads(result.decode()))\n",
    "        document['embedding'] = result[0]  # Assuming the API's output can be directly assigned\n",
    "        return document\n",
    "\n",
    "async def main(documents):\n",
    "    # Semaphore to limit concurrent requests. Adjust the number as needed.\n",
    "    semaphore = asyncio.BoundedSemaphore(MAX_WORKERS)\n",
    "\n",
    "    # Creating a list of tasks\n",
    "    tasks = [request(document, semaphore) for document in documents]\n",
    "    \n",
    "    # Using tqdm to show progress. It's been integrated into the async loop.\n",
    "    for f in tqdm(asyncio.as_completed(tasks), total=len(documents)):\n",
    "        await f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec4983af-65eb-4841-808a-3738fb4d682d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a2affdee8d46f3b0c1f691eaac4b89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings = 100 documents = 100\n",
      "0 min 21.33 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "# Get embeddings\n",
    "await main(documents)\n",
    "\n",
    "# Make sure we got it all\n",
    "count = 0\n",
    "for document in documents:\n",
    "    if 'embedding' in document.keys() and len(document['embedding']) == 768:\n",
    "        count += 1\n",
    "print(f'Embeddings = {count} documents = {len(documents)}')\n",
    "\n",
    "            \n",
    "# Print elapsed time\n",
    "elapsed_time = time.perf_counter() - start\n",
    "minutes, seconds = divmod(elapsed_time, 60)\n",
    "print(f\"{int(minutes)} min {seconds:.2f} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab97c7b-7bac-4bf5-9752-b528294dadc7",
   "metadata": {},
   "source": [
    "## æš‚åœæ¨ç†ç«¯ç‚¹\n",
    "\n",
    "ç°åœ¨æˆ‘ä»¬å·²ç»å®Œæˆäº†åµŒå…¥ï¼Œè®©æˆ‘ä»¬æš‚åœç«¯ç‚¹ï¼Œä»¥å…äº§ç”Ÿä»»ä½•é¢å¤–è´¹ç”¨ï¼ŒåŒæ—¶è¿™ä¹Ÿå…è®¸æˆ‘ä»¬åˆ†ææˆæœ¬ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "540a0978-7670-4ce3-95c1-3823cc113b85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Status: paused\n"
     ]
    }
   ],
   "source": [
    "endpoint = endpoint.pause()\n",
    "\n",
    "print(f\"Endpoint Status: {endpoint.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ad65b7-3da2-4113-9b95-8fb4e21ae793",
   "metadata": {},
   "source": [
    "# å°†æ›´æ–°åçš„æ•°æ®é›†æ¨é€åˆ° Hub\n",
    "ç°åœ¨æˆ‘ä»¬çš„æ–‡æ¡£å·²ç»æ›´æ–°äº†æˆ‘ä»¬æƒ³è¦çš„åµŒå…¥ã€‚é¦–å…ˆæˆ‘ä»¬éœ€è¦å°†å…¶è½¬æ¢å› `Dataset` æ ¼å¼ã€‚æˆ‘å‘ç°ä»å­—å…¸åˆ—è¡¨ -> `pd.DataFrame` -> `Dataset` è¿™æ¡è·¯å¾„æœ€ä¸ºç®€å•ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bb993f8-d624-4192-9626-8e9ed9888a1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(documents)\n",
    "dd = DatasetDict({'train': Dataset.from_pandas(df)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129760c8-cae1-4b1e-8216-f5152df8c536",
   "metadata": {},
   "source": [
    "æˆ‘é»˜è®¤å°†å…¶ä¸Šä¼ åˆ°ç”¨æˆ·çš„è´¦æˆ·ï¼ˆè€Œä¸æ˜¯ä¸Šä¼ åˆ°ç»„ç»‡ï¼‰ï¼Œä½†ä½ å¯ä»¥é€šè¿‡åœ¨ `repo_id` ä¸­è®¾ç½®ç”¨æˆ·æˆ–åœ¨é…ç½®ä¸­é€šè¿‡è®¾ç½® `DATASET_OUT` æ¥è‡ªç”±æ¨é€åˆ°ä»»ä½•ä½ æƒ³è¦çš„åœ°æ–¹ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f48e7c55-d5b7-4ed6-8516-272ae38716b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3af2e864770481db5adc3968500b5d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e063c42d8f4490c939bc64e626b507a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/823 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dd.push_to_hub(repo_id=DATASET_OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85ea2244-a4c6-4f04-b187-965a2fc356a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is at https://huggingface.co/datasets/derek-thomas/processed-subset-bestofredditorupdates\n"
     ]
    }
   ],
   "source": [
    "print(f'Dataset is at https://huggingface.co/datasets/{who[\"name\"]}/{DATASET_OUT}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41abea64-379d-49de-8d9a-355c2f4ce1ac",
   "metadata": {},
   "source": [
    "# åˆ†æä½¿ç”¨æƒ…å†µ\n",
    "1. å‰å¾€ä¸‹é¢æ‰“å°çš„ `dashboard_url`\n",
    "2. ç‚¹å‡»ä½¿ç”¨ä¸æˆæœ¬ (Usage & Cost) æ ‡ç­¾\n",
    "3. æŸ¥çœ‹ä½ å·²ç»èŠ±è´¹äº†å¤šå°‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16815445-3079-43da-b14e-b54176a07a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ui.endpoints.huggingface.co/HF-test-lab/endpoints/boru-jina-embeddings-demo-ie\n"
     ]
    }
   ],
   "source": [
    "dashboard_url = f'https://ui.endpoints.huggingface.co/{namespace}/endpoints/{ENDPOINT_NAME}'\n",
    "print(dashboard_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81096c6f-d12f-4781-84ec-9066cfa465b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit enter to continue with the notebook \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input(\"Hit enter to continue with the notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847d524e-9aa6-4a6f-a275-8a552e289818",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬å¯ä»¥çœ‹åˆ°åªèŠ±äº† `$0.04` !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b953d5be-2494-4ff8-be42-9daf00c99c41",
   "metadata": {},
   "source": [
    "\n",
    "# åˆ é™¤ç«¯ç‚¹\n",
    "ç°åœ¨æˆ‘ä»¬å·²ç»å®Œæˆäº†ï¼Œä¸å†éœ€è¦æˆ‘ä»¬çš„ç«¯ç‚¹äº†ã€‚æˆ‘ä»¬å¯ä»¥ä»¥ç¼–ç¨‹æ–¹å¼åˆ é™¤ç«¯ç‚¹ã€‚\n",
    "\n",
    "![Cost](https://huggingface.co/datasets/huggingface/cookbook-images/resolve/main/automatic_embedding_tei_inference_endpoints.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c310c0f3-6f12-4d5c-838b-3a4c1f2e54ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint deleted successfully\n"
     ]
    }
   ],
   "source": [
    "endpoint = endpoint.delete()\n",
    "\n",
    "if not endpoint:\n",
    "    print('Endpoint deleted successfully')\n",
    "else:\n",
    "    print('Delete Endpoint in manually') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
