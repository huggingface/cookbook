{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ä½¿ç”¨ TGI çš„æ¶ˆæ¯ API ä» OpenAI è¿ç§»åˆ° Open LLMs\n",
    "\n",
    "_ä½œè€…: [Andrew Reed](https://huggingface.co/andrewrreed)_\n",
    "\n",
    "è¿™ä¸ª notebook å±•ç¤ºäº†å¦‚ä½•è½»æ¾åœ°ä» OpenAI æ¨¡å‹è¿‡æ¸¡åˆ° Open LLMsï¼Œè€Œæ— éœ€é‡æ„ä»»ä½•ç°æœ‰ä»£ç ã€‚\n",
    "\n",
    "[æ–‡æœ¬ç”Ÿæˆæ¨ç†ï¼ˆTGIï¼‰](https://github.com/huggingface/text-generation-inference)ç°åœ¨æä¾›äº†ä¸€ä¸ª[æ¶ˆæ¯ API](https://huggingface.co/blog/tgi-messages-api)ï¼Œä½¿å…¶ä¸ OpenAI çš„èŠå¤©å®Œæˆ API çš„ç›´æ¥å…¼å®¹ã€‚è¿™æ„å‘³ç€ä»»ä½•ä½¿ç”¨ OpenAI çš„æ¨¡å‹ï¼ˆé€šè¿‡ OpenAI å®¢æˆ·ç«¯åº“æˆ–åƒ LangChain æˆ– LlamaIndex è¿™æ ·çš„ç¬¬ä¸‰æ–¹å·¥å…·ï¼‰çš„ç°æœ‰è„šæœ¬éƒ½å¯ä»¥ç›´æ¥æ›¿æ¢ä¸ºä½¿ç”¨è¿è¡Œåœ¨ TGI ç«¯ç‚¹ä¸Šçš„ä»»ä½•å¼€æº LLMï¼\n",
    "\n",
    "è¿™å…è®¸ä½ å¿«é€Ÿæµ‹è¯•å¹¶å—ç›Šäºå¼€æºæ¨¡å‹æä¾›çš„ä¼—å¤šä¼˜åŠ¿ã€‚ä¾‹å¦‚ï¼š\n",
    "\n",
    "- å¯¹æ¨¡å‹å’Œæ•°æ®çš„å®Œå…¨æ§åˆ¶å’Œé€æ˜åº¦\n",
    "\n",
    "- ä¸å†æ‹…å¿ƒé€Ÿç‡é™åˆ¶\n",
    "\n",
    "- èƒ½å¤Ÿæ ¹æ®ä½ çš„å…·ä½“éœ€æ±‚å®Œå…¨å®šåˆ¶ç³»ç»Ÿ\n",
    "\n",
    "åœ¨è¿™ä¸ª notebook ä¸­ï¼Œæˆ‘ä»¬å°†å‘ä½ å±•ç¤ºå…·ä½“æµç¨‹ï¼š\n",
    "\n",
    "1. [ä½¿ç”¨ TGI åˆ›å»ºæ¨ç†ç«¯ç‚¹æ¥éƒ¨ç½²æ¨¡å‹](#section_1)\n",
    "2. [ä½¿ç”¨ OpenAI å®¢æˆ·ç«¯åº“æŸ¥è¯¢æ¨ç†ç«¯ç‚¹](#section_2)\n",
    "3. [å°†ç«¯ç‚¹ä¸ LangChain å’Œ LlamaIndex å·¥ä½œæµç¨‹é›†æˆ](#section_3)\n",
    "\n",
    "**è®©æˆ‘ä»¬å¼€å§‹å§ï¼**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åˆå§‹åŒ–è®¾ç½®\n",
    "\n",
    "é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å®‰è£…ä¾èµ–é¡¹å’Œè®¾ç½®ä¸€ä¸ª HF API å¯†é’¥ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade -q huggingface_hub langchain langchain-community langchainhub langchain-openai llama-index chromadb bs4 sentence_transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "# enter API key\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HF_API_KEY = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_1\"></a>\n",
    "\n",
    "## 1. åˆ›å»ºä¸€ä¸ªæ¨ç†ç«¯ç‚¹\n",
    "\n",
    "ä¸€å¼€å§‹ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨ TGI å°†[Nous-Hermes-2-Mixtral-8x7B-DPO](https://huggingface.co/NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO)ï¼Œä¸€ä¸ªå¾®è°ƒçš„ Mixtral æ¨¡å‹ï¼Œéƒ¨ç½²åˆ°æ¨ç†ç«¯ç‚¹ã€‚\n",
    "\n",
    "æˆ‘ä»¬åªéœ€é€šè¿‡ UI çš„[å‡ æ¬¡ç‚¹å‡»](https://ui.endpoints.huggingface.co/new?vendor=aws&repository=NousResearch%2FNous-Hermes-2-Mixtral-8x7B-DPO&tgi_max_total_tokens=32000&tgi=true&tgi_max_input_length=1024&task=text-generation&instance_size=2xlarge&tgi_max_batch_prefill_tokens=2048&tgi_max_batch_total_tokens=1024000&no_suggested_compute=true&accelerator=gpu&region=us-east-1)ï¼Œå°±å¯ä»¥éƒ¨ç½²æ¨¡å‹ï¼Œæˆ–è€…åˆ©ç”¨ `huggingface_hub` Python åº“ä»¥ç¼–ç¨‹æ–¹å¼åˆ›å»ºå’Œç®¡ç†æ¨ç†ç«¯ç‚¹ã€‚\n",
    "\n",
    "åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ Hub åº“ï¼Œé€šè¿‡æŒ‡å®šç«¯ç‚¹åç§°å’Œæ¨¡å‹ä»“åº“ï¼Œä»¥åŠ `text-generation` ä»»åŠ¡ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ `protected` ç±»å‹ï¼Œå› æ­¤è®¿é—®éƒ¨ç½²çš„æ¨¡å‹å°†éœ€è¦ä¸€ä¸ªæœ‰æ•ˆçš„ Hugging Face tokenã€‚æˆ‘ä»¬è¿˜éœ€è¦é…ç½®ç¡¬ä»¶è¦æ±‚ï¼Œå¦‚ä¾›åº”å•†ã€åœ°åŒºã€åŠ é€Ÿå™¨ã€å®ä¾‹ç±»å‹å’Œå¤§å°ã€‚ä½ å¯ä»¥ä½¿ç”¨[this API call](https://api.endpoints.huggingface.cloud/#get-/v2/provider)æŸ¥çœ‹å¯ç”¨çš„èµ„æºé€‰é¡¹åˆ—è¡¨ï¼Œå¹¶åœ¨ç›®å½•ä¸­[è¿™é‡Œ](https://ui.endpoints.huggingface.co/catalog)æŸ¥çœ‹ä¸ºé€‰å®šæ¨¡å‹æ¨èé…ç½®ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import create_inference_endpoint\n",
    "\n",
    "endpoint = create_inference_endpoint(\n",
    "    \"nous-hermes-2-mixtral-8x7b-demo\",\n",
    "    repository=\"NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO\",\n",
    "    framework=\"pytorch\",\n",
    "    task=\"text-generation\",\n",
    "    accelerator=\"gpu\",\n",
    "    vendor=\"aws\",\n",
    "    region=\"us-east-1\",\n",
    "    type=\"protected\",\n",
    "    instance_type=\"p4de\",\n",
    "    instance_size=\"2xlarge\",\n",
    "    custom_image={\n",
    "        \"health_route\": \"/health\",\n",
    "        \"env\": {\n",
    "            \"MAX_INPUT_LENGTH\": \"4096\",\n",
    "            \"MAX_BATCH_PREFILL_TOKENS\": \"4096\",\n",
    "            \"MAX_TOTAL_TOKENS\": \"32000\",\n",
    "            \"MAX_BATCH_TOTAL_TOKENS\": \"1024000\",\n",
    "            \"MODEL_ID\": \"/repository\",\n",
    "        },\n",
    "        \"url\": \"ghcr.io/huggingface/text-generation-inference:sha-1734540\",  # must be >= 1.4.0\n",
    "    },\n",
    ")\n",
    "\n",
    "endpoint.wait()\n",
    "print(endpoint.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "éƒ¨ç½²å¯åŠ¨éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `.wait()` å·¥å…·æ¥é˜»å¡è¿è¡Œçº¿ç¨‹ï¼Œç›´åˆ°ç«¯ç‚¹è¾¾åˆ°æœ€ç»ˆçš„â€œè¿è¡Œâ€çŠ¶æ€ã€‚ä¸€æ—¦è¿è¡Œï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ UI æ’­æ”¾å™¨ä¸­ç¡®è®¤å…¶çŠ¶æ€å¹¶è¯•ç”¨ï¼š\n",
    "\n",
    "![IE UI Overview](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/messages-api/endpoint-overview.png)\n",
    "\n",
    "å¤ªå¥½äº†ï¼Œç°åœ¨æˆ‘ä»¬æœ‰ä¸€ä¸ªå¯ç”¨çš„ç«¯ç‚¹ï¼\n",
    "\n",
    "_æ³¨æ„ï¼šä½¿ç”¨ `huggingface_hub` éƒ¨ç½²æ—¶ï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼Œåœ¨15åˆ†é’Ÿç©ºé—²æ—¶é—´åï¼Œä½ çš„ç«¯ç‚¹ä¼šè‡ªåŠ¨ç¼©æ”¾åˆ°é›¶ï¼Œä»¥åœ¨éæ´»åŠ¨æœŸé—´ä¼˜åŒ–æˆæœ¬ã€‚æŸ¥çœ‹[ Hub Python åº“æ–‡æ¡£](https://huggingface.co/docs/huggingface_hub/guides/inference_endpoints)ä»¥äº†è§£å¯ç”¨äºç®¡ç†ç«¯ç‚¹ç”Ÿå‘½å‘¨æœŸçš„æ‰€æœ‰åŠŸèƒ½ã€‚_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_2\"></a>\n",
    "\n",
    "## 2. ä½¿ç”¨ OpenAI å®¢æˆ·ç«¯åº“æŸ¥è¯¢æ¨ç†ç«¯ç‚¹\n",
    "\n",
    "å¦‚ä¸Šæ‰€è¿°ï¼Œç”±äºæˆ‘ä»¬çš„æ¨¡å‹æ‰˜ç®¡åœ¨ TGI ä¸Šï¼Œç°åœ¨æ”¯æŒæ¶ˆæ¯ APIï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥ç›´æ¥ä½¿ç”¨ç†Ÿæ‚‰çš„ OpenAI å®¢æˆ·ç«¯åº“æ¥æŸ¥è¯¢å®ƒã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨ Python å®¢æˆ·ç«¯\n",
    "\n",
    "ä¸‹é¢çš„ä¾‹å­å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨[ OpenAI Python åº“](https://github.com/openai/openai-python)è¿›è¡Œè¿™ç§è½¬æ¢ã€‚åªéœ€å°† `<ENDPOINT_URL>` æ›¿æ¢ä¸ºä½ çš„ç«¯ç‚¹ URLï¼ˆç¡®ä¿åŒ…å« `v1/` åç¼€ï¼‰ï¼Œå¹¶å°† `<HF_API_KEY>` å­—æ®µå¡«å……ä¸ºæœ‰æ•ˆçš„ Hugging Face ç”¨æˆ· tokenã€‚`<ENDPOINT_URL>` å¯ä»¥ä»æ¨ç†ç«¯ç‚¹çš„ UI ä¸­è·å–ï¼Œæˆ–è€…ä»æˆ‘ä»¬ä¸Šé¢ä½¿ç”¨ `endpoint.url` åˆ›å»ºçš„ç«¯ç‚¹å¯¹è±¡ä¸­è·å–ã€‚\n",
    "\n",
    "ç„¶åæˆ‘ä»¬å¯ä»¥åƒå¾€å¸¸ä¸€æ ·ä½¿ç”¨å®¢æˆ·ç«¯ï¼Œä¼ é€’ä¸€ä¸ªæ¶ˆæ¯åˆ—è¡¨ä»¥ä»æˆ‘ä»¬çš„æ¨ç†ç«¯ç‚¹æµå¼ä¼ è¾“å“åº”ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open-source software is important due to a number of reasons, including:\n",
      "\n",
      "1. Collaboration: The collaborative nature of open-source software allows developers from around the world to work together, share their ideas and improve the code. This often results in faster progress and better software.\n",
      "\n",
      "2. Transparency: With open-source software, the code is publicly available, making it easy to see exactly how the software functions, and allowing users to determine if there are any security vulnerabilities.\n",
      "\n",
      "3. Customization: Being able to access the code also allows users to customize the software to better suit their needs. This makes open-source software incredibly versatile, as users can tweak it to suit their specific use case.\n",
      "\n",
      "4. Quality: Open-source software is often developed by large communities of dedicated developers, who work together to improve the software. This results in a higher level of quality than might be found in proprietary software.\n",
      "\n",
      "5. Cost: Open-source software is often provided free of charge, which makes it accessible to a wider range of users. This can be especially important for organizations with limited budgets for software.\n",
      "\n",
      "6. Shared Benefit: By sharing the code of open-source software, everyone can benefit from the hard work of the developers. This contributes to the overall advancement of technology, as users and developers work together to improve and build upon the software.\n",
      "\n",
      "In summary, open-source software provides a collaborative platform that leads to high-quality, customizable, and transparent software, all available at little or no cost, benefiting both individuals and the technology community as a whole.<|im_end|>"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "BASE_URL = endpoint.url\n",
    "\n",
    "# init the client but point it to TGI\n",
    "client = OpenAI(\n",
    "    base_url=os.path.join(BASE_URL, \"v1/\"),\n",
    "    api_key=HF_API_KEY,\n",
    ")\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"tgi\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Why is open-source software important?\"},\n",
    "    ],\n",
    "    stream=True,\n",
    "    max_tokens=500,\n",
    ")\n",
    "\n",
    "# iterate and print stream\n",
    "for message in chat_completion:\n",
    "    print(message.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨å¹•åï¼ŒTGI çš„æ¶ˆæ¯ API è‡ªåŠ¨ä½¿ç”¨å…¶[èŠå¤©æ¨¡æ¿](https://huggingface.co/docs/transformers/chat_templating)å°†æ¶ˆæ¯åˆ—è¡¨è½¬æ¢ä¸ºæ¨¡å‹æ‰€éœ€çš„æŒ‡ä»¤æ ¼å¼ã€‚\n",
    "\n",
    "_æ³¨æ„ï¼šæŸäº› OpenAI åŠŸèƒ½ï¼Œå¦‚å‡½æ•°è°ƒç”¨ï¼Œä¸ TGI ä¸å…¼å®¹ã€‚ç›®å‰ï¼Œæ¶ˆæ¯ API æ”¯æŒä»¥ä¸‹ chat completion å‚æ•°ï¼š`stream`ã€`max_new_tokens`ã€`frequency_penalty`ã€`logprobs`ã€`seed`ã€`temperature` å’Œ `top_p`._\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨ JavaScript å®¢æˆ·ç«¯\n",
    "\n",
    "è¿™é‡Œæ˜¯ä¸ä¸Šé¢ç›¸åŒçš„æµå¼ç¤ºä¾‹ï¼Œä½†æ˜¯ä½¿ç”¨äº†[ OpenAI Javascript/Typescript åº“](https://github.com/openai/openai-node)ã€‚\n",
    "\n",
    "\n",
    "```js\n",
    "import OpenAI from \"openai\";\n",
    "\n",
    "const openai = new OpenAI({\n",
    "  baseURL: \"<ENDPOINT_URL>\" + \"/v1/\", // replace with your endpoint url\n",
    "  apiKey: \"<HF_API_TOKEN>\", // replace with your token\n",
    "});\n",
    "\n",
    "async function main() {\n",
    "  const stream = await openai.chat.completions.create({\n",
    "    model: \"tgi\",\n",
    "    messages: [\n",
    "      { role: \"system\", content: \"You are a helpful assistant.\" },\n",
    "      { role: \"user\", content: \"Why is open-source software important?\" },\n",
    "    ],\n",
    "    stream: true,\n",
    "    max_tokens: 500,\n",
    "  });\n",
    "  for await (const chunk of stream) {\n",
    "    process.stdout.write(chunk.choices[0]?.delta?.content || \"\");\n",
    "  }\n",
    "}\n",
    "\n",
    "main();\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_3\"></a>\n",
    "\n",
    "## 3. ä¸ LangChain å’Œ LlamaIndex é›†æˆ\n",
    "\n",
    "ç°åœ¨ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•å°†è¿™ä¸ªæ–°åˆ›å»ºçš„ç«¯ç‚¹ä¸åƒ LangChain å’Œ LlamaIndex è¿™æ ·çš„æµè¡Œ RAG æ¡†æ¶ä¸€èµ·ä½¿ç”¨ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¦‚ä½•ä¸ LangChain ä¸€èµ·ä½¿ç”¨\n",
    "\n",
    "è¦åœ¨ [LangChain](https://python.langchain.com/docs/get_started/introduction) ä¸­ä½¿ç”¨ï¼Œåªéœ€åˆ›å»ºä¸€ä¸ª `ChatOpenAI` çš„å®ä¾‹ï¼Œå¹¶æŒ‰å¦‚ä¸‹æ–¹å¼ä¼ é€’ä½ çš„ `<ENDPOINT_URL>` å’Œ `<HF_API_TOKEN>`ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Open-source software is important for several reasons:\\n\\n1. Transparency: Open-source software allows users to see the underlying code, making it easier to understand how the software works and identify any potential security vulnerabilities or bugs. This transparency fosters trust between users and developers.\\n\\n2. Collaboration: Open-source projects encourage collaboration among developers, allowing them to work together to improve the software, fix issues, and add new features. This collective effort can lead to')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"tgi\",\n",
    "    openai_api_key=HF_API_KEY,\n",
    "    openai_api_base=os.path.join(BASE_URL, \"v1/\"),\n",
    ")\n",
    "llm.invoke(\"Why is open-source software important?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬èƒ½å¤Ÿç›´æ¥åˆ©ç”¨ä¸ OpenAI æ¨¡å‹ç›¸åŒçš„ `ChatOpenAI` ç±»ã€‚è¿™ä½¿å¾—æ‰€æœ‰ä¹‹å‰çš„ä»£ç åªéœ€æ›´æ”¹ä¸€è¡Œä»£ç ï¼Œå°±èƒ½ä¸æˆ‘ä»¬çš„ç«¯ç‚¹ä¸€èµ·å·¥ä½œã€‚\n",
    "\n",
    "ç°åœ¨ï¼Œè®©æˆ‘ä»¬åœ¨ç®€å•çš„ RAG æµæ°´çº¿ä¸­ä½¿ç”¨æˆ‘ä»¬çš„ Mixtral æ¨¡å‹ï¼Œæ¥å›ç­”ä¸€ä¸ªå…³äº HF åšå®¢å†…å®¹çš„é—®é¢˜ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content='To overcome this weakness, amongst other approaches, one can integrate the LLM into a system where it can call tools: such a system is called an LLM agent.\\nIn this post, we explain the inner workings of ReAct agents, then show how to build them using the ChatHuggingFace class recently integrated in LangChain. Finally, we benchmark several open-source LLMs against GPT-3.5 and GPT-4.', metadata={'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.', 'source': 'https://huggingface.co/blog/open-source-llms-as-agents', 'title': 'Open-source LLMs as LangChain Agents'}),\n",
       "  Document(page_content='Since the open-source models were not specifically fine-tuned for calling functions in the given output format, they are at a slight disadvantage compared to the OpenAI agents.\\nDespite this, some models perform really well! ğŸ’ª\\nHereâ€™s an example of Mixtral-8x7B answering the question: â€œWhich city has a larger population, Guiyang or Tacheng?â€\\nThought: To answer this question, I need to find the current populations of both Guiyang and Tacheng. I will use the search tool to find this information.\\nAction:\\n{', metadata={'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.', 'source': 'https://huggingface.co/blog/open-source-llms-as-agents', 'title': 'Open-source LLMs as LangChain Agents'}),\n",
       "  Document(page_content='Agents Showdown: how do open-source LLMs perform as general purpose reasoning agents?\\n\\t\\n\\nYou can find the code for this benchmark here.\\n\\n\\n\\n\\n\\n\\t\\tEvaluation\\n\\t\\n\\nWe want to measure how open-source LLMs perform as general purpose reasoning agents. Thus we select questions requiring using logic and the use of basic tools: a calculator and access to internet search.\\nThe final dataset is a combination of samples from 3 other datasets:', metadata={'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.', 'source': 'https://huggingface.co/blog/open-source-llms-as-agents', 'title': 'Open-source LLMs as LangChain Agents'}),\n",
       "  Document(page_content='Open-source LLMs as LangChain Agents\\n\\t\\n\\nPublished\\n\\t\\t\\t\\tJanuary 24, 2024\\nUpdate on GitHub\\n\\nm-ric\\nAymeric Roucher\\n\\n\\n\\n\\nJofthomas\\nJoffrey THOMAS\\n\\n\\n\\n\\nandrewrreed\\nAndrew Reed\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\tTL;DR\\n\\t\\n\\nOpen-source LLMs have now reached a performance level that makes them suitable reasoning engines for powering agent workflows: Mixtral even surpasses GPT-3.5 on our benchmark, and its performance could easily be further enhanced with fine-tuning.\\n\\n\\n\\n\\n\\n\\t\\tIntroduction', metadata={'description': 'Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science.', 'language': 'No language found.', 'source': 'https://huggingface.co/blog/open-source-llms-as-agents', 'title': 'Open-source LLMs as LangChain Agents'})],\n",
       " 'question': 'According to this article which open-source model is the best for an agent behaviour?',\n",
       " 'answer': 'According to the article, Mixtral-8x7B is an open-source LLM that performs really well as a general-purpose reasoning agent. It even surpasses GPT-3.5 on the benchmark in the article.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Load, chunk and index the contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://huggingface.co/blog/open-source-llms-as-agents\",),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# declare an HF embedding model\n",
    "hf_embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-large-en-v1.5\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=hf_embeddings)\n",
    "\n",
    "# Retrieve and generate using the relevant snippets of the blog\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)\n",
    "\n",
    "rag_chain_with_source.invoke(\n",
    "    \"According to this article which open-source model is the best for an agent behaviour?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¦‚ä½•ä¸ LlamaIndex ä¸€èµ·ä½¿ç”¨\n",
    "\n",
    "ç±»ä¼¼åœ°ï¼Œä½ ä¹Ÿå¯ä»¥åœ¨ [LlamaIndex](https://www.llamaindex.ai/) ä¸­ä½¿ç”¨ TGI ç«¯ç‚¹ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ `OpenAILike` ç±»ï¼Œå¹¶é€šè¿‡é…ç½®ä¸€äº›é¢å¤–çš„å‚æ•°ï¼ˆå³ `is_local`ã€`is_function_calling_model`ã€`is_chat_model`ã€`context_window`ï¼‰æ¥å®ä¾‹åŒ–å®ƒã€‚\n",
    "\n",
    "_æ³¨æ„ï¼šä¸Šä¸‹æ–‡çª—å£å‚æ•°åº”ä¸ä¹‹å‰ä¸ºç«¯ç‚¹çš„ `MAX_TOTAL_TOKENS` è®¾ç½®çš„å€¼ç›¸åŒ¹é…ã€‚_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionResponse(text='Open-source software is important for several reasons:\\n\\n1. Transparency: Open-source software allows users to see the source code, which means they can understand how the software works and how it processes data. This transparency helps build trust in the software and its developers.\\n\\n2. Collaboration: Open-source software encourages collaboration among developers, who can contribute to the code, fix bugs, and add new features. This collaborative approach often leads to faster development and', additional_kwargs={}, raw={'id': '', 'choices': [Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='Open-source software is important for several reasons:\\n\\n1. Transparency: Open-source software allows users to see the source code, which means they can understand how the software works and how it processes data. This transparency helps build trust in the software and its developers.\\n\\n2. Collaboration: Open-source software encourages collaboration among developers, who can contribute to the code, fix bugs, and add new features. This collaborative approach often leads to faster development and', role='assistant', function_call=None, tool_calls=None))], 'created': 1707342025, 'model': '/repository', 'object': 'text_completion', 'system_fingerprint': '1.4.0-sha-1734540', 'usage': CompletionUsage(completion_tokens=100, prompt_tokens=18, total_tokens=118)}, delta=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.llms import OpenAILike\n",
    "\n",
    "llm = OpenAILike(\n",
    "    model=\"tgi\",\n",
    "    api_key=HF_API_KEY,\n",
    "    api_base=BASE_URL + \"/v1/\",\n",
    "    is_chat_model=True,\n",
    "    is_local=False,\n",
    "    is_function_calling_model=False,\n",
    "    context_window=4096,\n",
    ")\n",
    "\n",
    "llm.complete(\"Why is open-source software important?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å®ƒåœ¨ç±»ä¼¼çš„ RAG æµæ°´çº¿ä¸­ã€‚è¯·è®°ä½ï¼Œä¹‹å‰åœ¨æ¨ç†ç«¯ç‚¹é€‰æ‹©çš„ `MAX_INPUT_LENGTH` å°†ç›´æ¥å½±å“æ¨¡å‹å¯ä»¥å¤„ç†çš„æ£€ç´¢åˆ°çš„æ•°æ®å—ï¼ˆ`similarity_top_k`ï¼‰çš„æ•°é‡ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import (\n",
    "    ServiceContext,\n",
    "    VectorStoreIndex,\n",
    ")\n",
    "from llama_index import download_loader\n",
    "from llama_index.embeddings import HuggingFaceEmbedding\n",
    "from llama_index.query_engine import CitationQueryEngine\n",
    "\n",
    "\n",
    "SimpleWebPageReader = download_loader(\"SimpleWebPageReader\")\n",
    "\n",
    "documents = SimpleWebPageReader(html_to_text=True).load_data(\n",
    "    [\"https://huggingface.co/blog/open-source-llms-as-agents\"]\n",
    ")\n",
    "\n",
    "# Load embedding model\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-large-en-v1.5\")\n",
    "\n",
    "# Pass LLM to pipeline\n",
    "service_context = ServiceContext.from_defaults(embed_model=embed_model, llm=llm)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, service_context=service_context, show_progress=True\n",
    ")\n",
    "\n",
    "# Query the index\n",
    "query_engine = CitationQueryEngine.from_args(\n",
    "    index,\n",
    "    similarity_top_k=2,\n",
    ")\n",
    "response = query_engine.query(\n",
    "    \"According to this article which open-source model is the best for an agent behaviour?\"\n",
    ")\n",
    "\n",
    "response.response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ€»ç»“\n",
    "\n",
    "å®Œæˆç«¯ç‚¹ä½¿ç”¨åï¼Œä½ å¯ä»¥æš‚åœæˆ–åˆ é™¤å®ƒã€‚è¿™ä¸€æ­¥å¯ä»¥é€šè¿‡ UI å®Œæˆï¼Œæˆ–è€…åƒä¸‹é¢è¿™æ ·ä»¥ç¼–ç¨‹æ–¹å¼å®Œæˆã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pause our running endpoint\n",
    "endpoint.pause()\n",
    "\n",
    "# optionally delete\n",
    "# endpoint.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
