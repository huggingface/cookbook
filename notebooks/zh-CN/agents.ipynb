{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ä½¿ç”¨ Transformers Agents æ„å»ºå…·æœ‰å·¥å…·è°ƒç”¨è¶…èƒ½åŠ›çš„æ™ºèƒ½ä½“ ğŸ¦¸\n",
    "\n",
    "_ä½œè€…: [Aymeric Roucher](https://huggingface.co/m-ric)_\n",
    "\n",
    "\n",
    "è¿™ä¸ª notebook å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ [**Transformers Agents**](https://huggingface.co/docs/transformers/en/agents) æ¥æ„å»ºå‡ºè‰²çš„**æ™ºèƒ½ä½“**ï¼\n",
    "\n",
    "ä»€ä¹ˆæ˜¯**æ™ºèƒ½ä½“**ï¼Ÿæ™ºèƒ½ä½“æ˜¯ç”±å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„ç³»ç»Ÿï¼Œå®ƒä»¬ä½¿å¾— LLMï¼ˆé€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æç¤ºå’Œè¾“å‡ºè§£æï¼‰èƒ½å¤Ÿä½¿ç”¨ç‰¹å®šçš„*å·¥å…·*æ¥è§£å†³é—®é¢˜ã€‚\n",
    "\n",
    "è¿™äº›*å·¥å…·*åŸºæœ¬ä¸Šæ˜¯ LLM è‡ªèº«æ— æ³•å¾ˆå¥½æ‰§è¡Œçš„åŠŸèƒ½ï¼šä¾‹å¦‚ï¼Œå¯¹äºåƒ [Llama-3-70B](https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct) è¿™æ ·çš„æ–‡æœ¬ç”Ÿæˆ LLMï¼Œè¿™å¯èƒ½æ˜¯ä¸€ä¸ªå›¾åƒç”Ÿæˆå·¥å…·ã€ç½‘ç»œæœç´¢å·¥å…·ã€è®¡ç®—å™¨...\n",
    "\n",
    "ä»€ä¹ˆæ˜¯ **Transformers Agents** ï¼Ÿå®ƒæ˜¯æˆ‘ä»¬ `transformers` åº“çš„ä¸€ä¸ªæ‰©å±•ï¼Œæä¾›äº†æ„å»ºè‡ªå·±çš„æ™ºèƒ½ä½“çš„æ„å»ºå—ï¼åœ¨[æ–‡æ¡£](https://huggingface.co/docs/transformers/en/agents)ä¸­äº†è§£æ›´å¤šä¿¡æ¯ã€‚\n",
    "\n",
    "è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•ä½¿ç”¨å®ƒï¼Œä»¥åŠå®ƒèƒ½è§£å†³å“ªäº›ç”¨ä¾‹ã€‚\n",
    "\n",
    "æˆ‘ä»¬ä»æºä»£ç å®‰è£… transformers agents ï¼Œä½ å¯ä»¥ä½¿ç”¨ `pip install transformers[agents]` è½»æ¾å®‰è£…ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"git+https://github.com/huggingface/transformers.git#egg=transformers[agents]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets huggingface_hub langchain sentence-transformers faiss-cpu serpapi google-search-results openai -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ğŸï¸ å¤šæ¨¡æ€ + ğŸŒ ç½‘ç»œæµè§ˆåŠ©æ‰‹\n",
    "\n",
    "å¯¹äºè¿™ä¸ªç”¨ä¾‹ï¼Œæˆ‘ä»¬æƒ³è¦å±•ç¤ºä¸€ä¸ªèƒ½å¤Ÿæµè§ˆç½‘ç»œå¹¶èƒ½å¤Ÿç”Ÿæˆå›¾åƒçš„æ™ºèƒ½ä½“ã€‚\n",
    "\n",
    "ä¸ºäº†æ„å»ºå®ƒï¼Œæˆ‘ä»¬åªéœ€è¦å‡†å¤‡ä¸¤ä¸ªå·¥å…·ï¼šå›¾åƒç”Ÿæˆå’Œç½‘ç»œæœç´¢ã€‚\n",
    "- å¯¹äºå›¾åƒç”Ÿæˆï¼Œæˆ‘ä»¬ä» Hub åŠ è½½ä¸€ä¸ªå·¥å…·ï¼Œè¯¥å·¥å…·ä½¿ç”¨ HF æ¨ç† APIï¼ˆæ— æœåŠ¡å™¨ï¼‰ä½¿ç”¨ Stable Diffusion ç”Ÿæˆå›¾åƒã€‚\n",
    "- å¯¹äºç½‘ç»œæœç´¢ï¼Œæˆ‘ä»¬åŠ è½½ä¸€ä¸ª LangChain å·¥å…·ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m======== New task ========\u001b[0m\n",
      "\u001b[37;1mGenerate me a photo of the car that James bond drove in the latest movie.\u001b[0m\n",
      "\u001b[33;1m==== Agent is executing the code below:\u001b[0m\n",
      "\u001b[0m\u001b[38;5;7mlatest_movie\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;109;01m=\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;7msearch\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;144m\"\u001b[39m\u001b[38;5;144mWhat is the latest James Bond movie?\u001b[39m\u001b[38;5;144m\"\u001b[39m\u001b[38;5;7m)\u001b[39m\n",
      "\u001b[38;5;109mprint\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;144m\"\u001b[39m\u001b[38;5;144mLatest James Bond movie:\u001b[39m\u001b[38;5;144m\"\u001b[39m\u001b[38;5;7m,\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;7mlatest_movie\u001b[39m\u001b[38;5;7m)\u001b[39m\n",
      "\u001b[38;5;7mbond_car\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;109;01m=\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;7msearch\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;144m\"\u001b[39m\u001b[38;5;144mWhat car did James Bond drive in the latest movie?\u001b[39m\u001b[38;5;144m\"\u001b[39m\u001b[38;5;7m)\u001b[39m\n",
      "\u001b[38;5;109mprint\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;144m\"\u001b[39m\u001b[38;5;144mJames Bond\u001b[39m\u001b[38;5;144m'\u001b[39m\u001b[38;5;144ms car:\u001b[39m\u001b[38;5;144m\"\u001b[39m\u001b[38;5;7m,\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;7mbond_car\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[0m\n",
      "\u001b[33;1m====\u001b[0m\n",
      "\u001b[33;1mPrint outputs:\u001b[0m\n",
      "\u001b[32;20mLatest James Bond movie: No Time to Die\n",
      "James Bond's car: Aston Martin DB5\n",
      "\u001b[0m\n",
      "\u001b[33;1m==== Agent is executing the code below:\u001b[0m\n",
      "\u001b[0m\u001b[38;5;7mimage\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;109;01m=\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;7mimage_generator\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;144m\"\u001b[39m\u001b[38;5;144mA high-res, photorealistic image of the Aston Martin DB5 driven by James Bond in No Time to Die\u001b[39m\u001b[38;5;144m\"\u001b[39m\u001b[38;5;7m)\u001b[39m\n",
      "\u001b[38;5;7mfinal_answer\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;7mimage\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[0m\n",
      "\u001b[33;1m====\u001b[0m\n",
      "\u001b[33;1mPrint outputs:\u001b[0m\n",
      "\u001b[32;20m\u001b[0m\n",
      "\u001b[33;1m>>> Final answer:\u001b[0m\n",
      "\u001b[32;20m/var/folders/6m/9b1tts6d5w960j80wbw9tx3m0000gn/T/tmptcdd2ra6/2bf48fc0-6fff-4e86-8fb5-85b3221bc0c8.png\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from transformers import Tool, load_tool, ReactCodeAgent, HfEngine\n",
    "\n",
    "# Import tool from Hub\n",
    "image_generation_tool = load_tool(\"m-ric/text-to-image\")\n",
    "\n",
    "# Import tool from LangChain\n",
    "from langchain.agents import load_tools\n",
    "\n",
    "search_tool = Tool.from_langchain(load_tools([\"serpapi\"])[0])\n",
    "\n",
    "\n",
    "llm_engine = HfEngine(\"meta-llama/Meta-Llama-3-70B-Instruct\")\n",
    "# Initialize the agent with both tools\n",
    "agent = ReactCodeAgent(\n",
    "    tools=[image_generation_tool, search_tool], llm_engine=llm_engine\n",
    ")\n",
    "\n",
    "# Run it!\n",
    "result = agent.run(\n",
    "    \"Generate me a photo of the car that James bond drove in the latest movie.\",\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of an Aston Martin DB5](https://huggingface.co/datasets/huggingface/cookbook-images/resolve/main/agents_db5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ğŸ“šğŸ’¬ å¸¦æœ‰è¿­ä»£æŸ¥è¯¢ä¼˜åŒ–å’Œæ¥æºé€‰æ‹©çš„ RAG\n",
    "å¿«é€Ÿå®šä¹‰ï¼šæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ˜¯ ___â€œä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥å›ç­”ç”¨æˆ·æŸ¥è¯¢ï¼Œä½†åŸºäºä»çŸ¥è¯†åº“æ£€ç´¢åˆ°çš„ä¿¡æ¯æ¥æ„å»ºç­”æ¡ˆâ€___ã€‚\n",
    "\n",
    "è¿™ç§æ–¹æ³•ç›¸æ¯”ä½¿ç”¨æ™®é€šæˆ–å¾®è°ƒçš„ LLM æœ‰è®¸å¤šä¼˜åŠ¿ï¼šåˆ—ä¸¾ä¸€äº›ï¼Œå®ƒå…è®¸å°†ç­”æ¡ˆå»ºç«‹åœ¨çœŸå®äº‹å®çš„åŸºç¡€ä¸Šå¹¶å‡å°‘è™šæ„ï¼Œå®ƒå…è®¸ä¸º LLM æä¾›ç‰¹å®šé¢†åŸŸçš„çŸ¥è¯†ï¼Œå¹¶ä¸”å®ƒå…è®¸å¯¹çŸ¥è¯†åº“ä¸­çš„ä¿¡æ¯è®¿é—®è¿›è¡Œç»†ç²’åº¦æ§åˆ¶ã€‚\n",
    "\n",
    "- ç°åœ¨å‡è®¾æˆ‘ä»¬æƒ³è¦æ‰§è¡Œ RAGï¼Œä½†å¢åŠ äº†åŠ¨æ€ç”ŸæˆæŸäº›å‚æ•°çš„çº¦æŸã€‚ä¾‹å¦‚ï¼Œæ ¹æ®ç”¨æˆ·æŸ¥è¯¢ï¼Œæˆ‘ä»¬å¯èƒ½æƒ³è¦å°†æœç´¢é™åˆ¶åœ¨çŸ¥è¯†åº“çš„ç‰¹å®šå­é›†ï¼Œæˆ–è€…æˆ‘ä»¬å¯èƒ½æƒ³è¦è°ƒæ•´æ£€ç´¢åˆ°çš„æ–‡æ¡£æ•°é‡ã€‚éš¾ç‚¹åœ¨äºï¼š**å¦‚ä½•æ ¹æ®ç”¨æˆ·æŸ¥è¯¢åŠ¨æ€è°ƒæ•´è¿™äº›å‚æ•°ï¼Ÿ**\n",
    "\n",
    "- RAG çš„ä¸€ä¸ªå¸¸è§å¤±è´¥æ¡ˆä¾‹æ˜¯åŸºäºç”¨æˆ·æŸ¥è¯¢çš„æ£€ç´¢æ²¡æœ‰è¿”å›ä»»ä½•ç›¸å…³çš„æ”¯æŒæ–‡æ¡£ã€‚**æœ‰æ²¡æœ‰ä¸€ç§æ–¹æ³•ï¼Œåœ¨ä¹‹å‰çš„ç»“æœä¸ç›¸å…³æ—¶ï¼Œé€šè¿‡ä¿®æ”¹æŸ¥è¯¢é‡æ–°è°ƒç”¨æ£€ç´¢å™¨æ¥è¿›è¡Œè¿­ä»£ï¼Ÿ**\n",
    "\n",
    "ğŸ”§ å¥½å§ï¼Œæˆ‘ä»¬å¯ä»¥ä»¥ç®€å•çš„æ–¹å¼è§£å†³ä¸Šè¿°é—®é¢˜ï¼šæˆ‘ä»¬å°†**è®©æˆ‘ä»¬çš„æ™ºèƒ½ä½“æ§åˆ¶æ£€ç´¢å™¨çš„å‚æ•°ï¼**\n",
    "\n",
    "â¡ï¸ è®©æˆ‘ä»¬å±•ç¤ºå¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹ã€‚æˆ‘ä»¬é¦–å…ˆåŠ è½½ä¸€ä¸ªæˆ‘ä»¬æƒ³è¦æ‰§è¡Œ RAG çš„çŸ¥è¯†åº“ï¼šè¿™ä¸ªæ•°æ®é›†æ˜¯è®¸å¤š `huggingface` åŒ…çš„æ–‡æ¡£é¡µé¢æ±‡æ€»ï¼Œä»¥ markdown æ ¼å¼å­˜å‚¨ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "knowledge_base = datasets.load_dataset(\"m-ric/huggingface_doc\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨æˆ‘ä»¬é€šè¿‡å¤„ç†æ•°æ®é›†å¹¶å°†å…¶å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“ä¸­æ¥å‡†å¤‡çŸ¥è¯†åº“ï¼Œä»¥ä¾¿æ£€ç´¢å™¨ä½¿ç”¨ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ LangChainï¼Œå› ä¸ºå®ƒå…·æœ‰ç”¨äºå‘é‡æ•°æ®åº“çš„ä¼˜ç§€å·¥å…·ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "source_docs = [\n",
    "    Document(page_content=doc[\"text\"], metadata={\"source\": doc[\"source\"].split(\"/\")[1]})\n",
    "    for doc in knowledge_base\n",
    "]\n",
    "\n",
    "docs_processed = RecursiveCharacterTextSplitter(chunk_size=500).split_documents(\n",
    "    source_docs\n",
    ")[:1000]\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"thenlper/gte-small\")\n",
    "vectordb = FAISS.from_documents(documents=docs_processed, embedding=embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨æˆ‘ä»¬å·²ç»å‡†å¤‡å¥½äº†æ•°æ®åº“ï¼Œè®©æˆ‘ä»¬æ„å»ºä¸€ä¸ªåŸºäºå®ƒå›ç­”ç”¨æˆ·æŸ¥è¯¢çš„ RAG ç³»ç»Ÿï¼\n",
    "\n",
    "æˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„ç³»ç»Ÿæ ¹æ®æŸ¥è¯¢åªä»æœ€ç›¸å…³çš„ä¿¡æ¯æ¥æºä¸­é€‰æ‹©ã€‚\n",
    "\n",
    "æˆ‘ä»¬çš„æ–‡æ¡£é¡µé¢æ¥è‡ªä»¥ä¸‹æ¥æºï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['evaluate', 'course', 'deep-rl-class', 'peft', 'hf-endpoints-documentation', 'blog', 'gradio', 'datasets', 'datasets-server', 'transformers', 'optimum', 'hub-docs', 'pytorch-image-models', 'diffusers']\n"
     ]
    }
   ],
   "source": [
    "all_sources = list(set([doc.metadata[\"source\"] for doc in docs_processed]))\n",
    "print(all_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers.agents import Tool\n",
    "from langchain_core.vectorstores import VectorStore\n",
    "\n",
    "\n",
    "class RetrieverTool(Tool):\n",
    "    name = \"retriever\"\n",
    "    description = \"Retrieves some documents from the knowledge base that have the closest embeddings to the input query.\"\n",
    "    inputs = {\n",
    "        \"query\": {\n",
    "            \"type\": \"text\",\n",
    "            \"description\": \"The query to perform. This should be semantically close to your target documents. Use the affirmative form rather than a question.\",\n",
    "        },\n",
    "        \"source\": {\"type\": \"text\", \"description\": \"\"},\n",
    "        \"number_of_documents\": {\n",
    "            \"type\": \"text\",\n",
    "            \"description\": \"the number of documents to retrieve. Stay under 10 to avoid drowning in docs\",\n",
    "        },\n",
    "    }\n",
    "    output_type = \"text\"\n",
    "\n",
    "    def __init__(self, vectordb: VectorStore, all_sources: str, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.vectordb = vectordb\n",
    "        self.inputs[\"source\"][\n",
    "            \"description\"\n",
    "        ] = f\"The source of the documents to search, as a str representation of a list. Possible values in the list are: {all_sources}. If this argument is not provided, all sources will be searched.\"\n",
    "\n",
    "    def forward(self, query: str, source: str = None, number_of_documents=7) -> str:\n",
    "        assert isinstance(query, str), \"Your search query must be a string\"\n",
    "        number_of_documents = int(number_of_documents)\n",
    "\n",
    "        if source:\n",
    "            if isinstance(source, str) and \"[\" not in str(\n",
    "                source\n",
    "            ):  # if the source is not representing a list\n",
    "                source = [source]\n",
    "            source = json.loads(str(source).replace(\"'\", '\"'))\n",
    "\n",
    "        docs = self.vectordb.similarity_search(\n",
    "            query,\n",
    "            filter=({\"source\": source} if source else None),\n",
    "            k=number_of_documents,\n",
    "        )\n",
    "\n",
    "        if len(docs) == 0:\n",
    "            return \"No documents found with this filtering. Try removing the source filter.\"\n",
    "        return \"Retrieved documents:\\n\\n\" + \"\\n===Document===\\n\".join(\n",
    "            [doc.page_content for doc in docs]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¯é€‰ï¼šå°†ä½ çš„æ£€ç´¢å™¨å·¥å…·åˆ†äº«åˆ° Hub\n",
    "\n",
    "è¦å°†ä½ çš„å·¥å…·åˆ†äº«åˆ° Hubï¼Œé¦–å…ˆå°†æ£€ç´¢å™¨å·¥å…·å®šä¹‰å•å…ƒæ ¼ä¸­çš„ä»£ç å¤åˆ¶ç²˜è´´åˆ°ä¸€ä¸ªåä¸ºä¾‹å¦‚ `retriever.py` çš„æ–°æ–‡ä»¶ä¸­ã€‚\n",
    "\n",
    "å½“å·¥å…·ä»å•ç‹¬çš„æ–‡ä»¶åŠ è½½åï¼Œä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç å°†å…¶æ¨é€åˆ° Hubï¼ˆç¡®ä¿ä½¿ç”¨å…·æœ‰`å†™å…¥`è®¿é—®æƒé™çš„ token ç™»å½•ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share_to_hub = False\n",
    "\n",
    "if share_to_hub:\n",
    "    from huggingface_hub import login\n",
    "    from retriever import RetrieverTool\n",
    "\n",
    "    login(\"your_token\")\n",
    "\n",
    "    tool = RetrieverTool(vectordb, all_sources)\n",
    "\n",
    "    tool.push_to_hub(repo_id=\"m-ric/retriever-tool\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è¿è¡Œæ™ºèƒ½ä½“!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/spaces/m-ric/retriever-tool:\n",
      "- retriever.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "\u001b[33;1m======== New task ========\u001b[0m\n",
      "\u001b[37;1mPlease show me a LORA finetuning script\u001b[0m\n",
      "\u001b[33;1mCalling tool: 'retriever' with arguments: {'number_of_documents': '5', 'query': 'LORA finetuning script', 'source': \"['transformers', 'blog']\"}\u001b[0m\n",
      "\u001b[33;1mCalling tool: 'retriever' with arguments: {'number_of_documents': '5', 'query': 'LORA finetuning script'}\u001b[0m\n",
      "\u001b[33;1mCalling tool: 'retriever' with arguments: {'number_of_documents': '5', 'query': 'train_text_to_image_lora.py'}\u001b[0m\n",
      "\u001b[33;1mCalling tool: 'final_answer' with arguments: https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image_lora.py\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output:\n",
      "https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image_lora.py\n"
     ]
    }
   ],
   "source": [
    "from transformers.agents import HfEngine, ReactJsonAgent, load_tool\n",
    "\n",
    "llm_engine = HfEngine(\"meta-llama/Meta-Llama-3-70B-Instruct\")\n",
    "\n",
    "retriever_tool = load_tool(\n",
    "    \"m-ric/retriever-tool\", vectordb=vectordb, all_sources=all_sources\n",
    ")\n",
    "agent = ReactJsonAgent(tools=[retriever_tool], llm_engine=llm_engine, verbose=0)\n",
    "\n",
    "agent_output = agent.run(\"Please show me a LORA finetuning script\")\n",
    "\n",
    "print(\"Final output:\")\n",
    "print(agent_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿé¦–å…ˆï¼Œæ™ºèƒ½ä½“å¯åŠ¨äº†æ£€ç´¢å™¨ï¼Œå¹¶è€ƒè™‘äº†ç‰¹å®šçš„æ¥æºï¼ˆ`['transformers', 'blog']`ï¼‰ã€‚\n",
    "\n",
    "ä½†æ˜¯è¿™æ¬¡æ£€ç´¢æ²¡æœ‰äº§ç”Ÿè¶³å¤Ÿçš„ç»“æœ â‡’ æ²¡å…³ç³»ï¼æ™ºèƒ½ä½“å¯ä»¥è¿­ä»£ä¹‹å‰çš„ç»“æœï¼Œå› æ­¤å®ƒåªæ˜¯ç”¨ä¸é‚£ä¹ˆä¸¥æ ¼çš„æœç´¢å‚æ•°é‡æ–°è¿è¡Œäº†å®ƒçš„æ£€ç´¢ã€‚\n",
    "\n",
    "å› æ­¤ï¼Œç ”ç©¶æˆåŠŸäº†ï¼\n",
    "\n",
    "è¯·æ³¨æ„ï¼Œ**ä½¿ç”¨è°ƒç”¨æ£€ç´¢å™¨ä½œä¸ºå·¥å…·å¹¶å¯ä»¥åŠ¨æ€ä¿®æ”¹æŸ¥è¯¢å’Œå…¶ä»–æ£€ç´¢å‚æ•°çš„ LLM æ™ºèƒ½ä½“**æ˜¯ RAG çš„**æ›´ä¸€èˆ¬çš„è¡¨è¿°**ï¼Œè¿™ä¹Ÿæ¶µç›–äº†åƒè¿­ä»£æŸ¥è¯¢ä¼˜åŒ–è¿™æ ·çš„è®¸å¤š RAG æ”¹è¿›æŠ€æœ¯ã€‚\n",
    "\n",
    "## 3. ğŸ’» è°ƒè¯• Python ä»£ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m======== New task ========\u001b[0m\n",
      "\u001b[37;1mI have some code that creates a bug: please debug it and return the final code\n",
      "You have been provided with these initial arguments: {'code': '\\nlist=[0, 1, 2]\\n\\nfor i in range(4):\\n    print(list(i))\\n'}.\u001b[0m\n",
      "\u001b[33;1m==== Agent is executing the code below:\u001b[0m\n",
      "\u001b[0m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;109;01m=\u001b[39;00m\u001b[38;5;7m[\u001b[39m\u001b[38;5;139m0\u001b[39m\u001b[38;5;7m,\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;139m1\u001b[39m\u001b[38;5;7m,\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;139m2\u001b[39m\u001b[38;5;7m]\u001b[39m\n",
      "\u001b[38;5;109mprint\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;7m)\u001b[39m\n",
      "\u001b[38;5;109;01mfor\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;7mi\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;109;01min\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;109mrange\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;139m4\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[38;5;7m:\u001b[39m\n",
      "\u001b[38;5;7m    \u001b[39m\u001b[38;5;109mprint\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;7m[\u001b[39m\u001b[38;5;7mi\u001b[39m\u001b[38;5;7m]\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[0m\n",
      "\u001b[33;1m====\u001b[0m\n",
      "\u001b[31;20mFailed while trying to execute the code below:\n",
      "\u001b[0mlist=[0, 1, 2]\n",
      "print(list)\n",
      "for i in range(4):\n",
      "    print(list[i])\u001b[0m\n",
      "This failed due to the following error:\n",
      "list index out of range\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aymeric/Documents/Code/original_transformers/transformers/src/transformers/agents/agents.py\", line 823, in step\n",
      "    result = self.python_evaluator(code_action, available_tools, state=self.state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/aymeric/Documents/Code/original_transformers/transformers/src/transformers/agents/python_interpreter.py\", line 511, in evaluate_python_code\n",
      "    line_result = evaluate_ast(node, state, tools)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/aymeric/Documents/Code/original_transformers/transformers/src/transformers/agents/python_interpreter.py\", line 404, in evaluate_ast\n",
      "    return evaluate_for(expression, state, tools)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/aymeric/Documents/Code/original_transformers/transformers/src/transformers/agents/python_interpreter.py\", line 313, in evaluate_for\n",
      "    line_result = evaluate_ast(node, state, tools)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/aymeric/Documents/Code/original_transformers/transformers/src/transformers/agents/python_interpreter.py\", line 401, in evaluate_ast\n",
      "    return evaluate_ast(expression.value, state, tools)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/aymeric/Documents/Code/original_transformers/transformers/src/transformers/agents/python_interpreter.py\", line 365, in evaluate_ast\n",
      "    return evaluate_call(expression, state, tools)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/aymeric/Documents/Code/original_transformers/transformers/src/transformers/agents/python_interpreter.py\", line 215, in evaluate_call\n",
      "    args = [evaluate_ast(arg, state, tools) for arg in call.args]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/aymeric/Documents/Code/original_transformers/transformers/src/transformers/agents/python_interpreter.py\", line 423, in evaluate_ast\n",
      "    return evaluate_subscript(expression, state, tools)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/aymeric/Documents/Code/original_transformers/transformers/src/transformers/agents/python_interpreter.py\", line 236, in evaluate_subscript\n",
      "    return value[int(index)]\n",
      "           ~~~~~^^^^^^^^^^^^\n",
      "IndexError: list index out of range\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aymeric/Documents/Code/original_transformers/transformers/src/transformers/agents/agents.py\", line 623, in run\n",
      "    final_answer = self.step()\n",
      "                   ^^^^^^^^^^^\n",
      "  File \"/Users/aymeric/Documents/Code/original_transformers/transformers/src/transformers/agents/agents.py\", line 832, in step\n",
      "    raise AgentExecutionError(error_msg)\n",
      "transformers.agents.agents.AgentExecutionError: Failed while trying to execute the code below:\n",
      "\u001b[0mlist=[0, 1, 2]\n",
      "print(list)\n",
      "for i in range(4):\n",
      "    print(list[i])\u001b[0m\n",
      "This failed due to the following error:\n",
      "list index out of range\n",
      "\u001b[33;1m==== Agent is executing the code below:\u001b[0m\n",
      "\u001b[0m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;109;01m=\u001b[39;00m\u001b[38;5;7m[\u001b[39m\u001b[38;5;139m0\u001b[39m\u001b[38;5;7m,\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;139m1\u001b[39m\u001b[38;5;7m,\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;139m2\u001b[39m\u001b[38;5;7m]\u001b[39m\n",
      "\u001b[38;5;109mprint\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;7m)\u001b[39m\n",
      "\u001b[38;5;109;01mfor\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;7mi\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;109;01min\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;109mrange\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;139m3\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[38;5;7m:\u001b[39m\n",
      "\u001b[38;5;7m    \u001b[39m\u001b[38;5;109mprint\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;7m[\u001b[39m\u001b[38;5;7mi\u001b[39m\u001b[38;5;7m]\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[0m\n",
      "\u001b[33;1m====\u001b[0m\n",
      "\u001b[33;1mPrint outputs:\u001b[0m\n",
      "\u001b[32;20m[0, 1, 2]\n",
      "0\n",
      "1\n",
      "2\n",
      "\u001b[0m\n",
      "\u001b[33;1m==== Agent is executing the code below:\u001b[0m\n",
      "\u001b[0m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;109;01m=\u001b[39;00m\u001b[38;5;7m[\u001b[39m\u001b[38;5;139m0\u001b[39m\u001b[38;5;7m,\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;139m1\u001b[39m\u001b[38;5;7m,\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;139m2\u001b[39m\u001b[38;5;7m]\u001b[39m\n",
      "\u001b[38;5;109mprint\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;7m)\u001b[39m\n",
      "\u001b[38;5;109;01mfor\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;7mi\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;109;01min\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;109mrange\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;139m3\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[38;5;7m:\u001b[39m\n",
      "\u001b[38;5;7m    \u001b[39m\u001b[38;5;109mprint\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;7m[\u001b[39m\u001b[38;5;7mi\u001b[39m\u001b[38;5;7m]\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[0m\n",
      "\u001b[33;1m====\u001b[0m\n",
      "\u001b[33;1mPrint outputs:\u001b[0m\n",
      "\u001b[32;20m[0, 1, 2]\n",
      "0\n",
      "1\n",
      "2\n",
      "\u001b[0m\n",
      "\u001b[33;1m==== Agent is executing the code below:\u001b[0m\n",
      "\u001b[0m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;109;01m=\u001b[39;00m\u001b[38;5;7m[\u001b[39m\u001b[38;5;139m0\u001b[39m\u001b[38;5;7m,\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;139m1\u001b[39m\u001b[38;5;7m,\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;139m2\u001b[39m\u001b[38;5;7m]\u001b[39m\n",
      "\u001b[38;5;109mprint\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;7m)\u001b[39m\n",
      "\u001b[38;5;109;01mfor\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;7mi\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;109;01min\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;109mrange\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;109mlen\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[38;5;7m:\u001b[39m\n",
      "\u001b[38;5;7m    \u001b[39m\u001b[38;5;109mprint\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;7m[\u001b[39m\u001b[38;5;7mi\u001b[39m\u001b[38;5;7m]\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[0m\n",
      "\u001b[33;1m====\u001b[0m\n",
      "\u001b[33;1mPrint outputs:\u001b[0m\n",
      "\u001b[32;20m[0, 1, 2]\n",
      "0\n",
      "1\n",
      "2\n",
      "\u001b[0m\n",
      "\u001b[33;1m==== Agent is executing the code below:\u001b[0m\n",
      "\u001b[0m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;109;01m=\u001b[39;00m\u001b[38;5;7m[\u001b[39m\u001b[38;5;139m0\u001b[39m\u001b[38;5;7m,\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;139m1\u001b[39m\u001b[38;5;7m,\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;139m2\u001b[39m\u001b[38;5;7m]\u001b[39m\n",
      "\u001b[38;5;109mprint\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;7m)\u001b[39m\n",
      "\u001b[38;5;109;01mfor\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;7mi\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;109;01min\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;109mrange\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;139m3\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[38;5;7m:\u001b[39m\n",
      "\u001b[38;5;7m    \u001b[39m\u001b[38;5;109mprint\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;7m[\u001b[39m\u001b[38;5;7mi\u001b[39m\u001b[38;5;7m]\u001b[39m\u001b[38;5;7m)\u001b[39m\n",
      "\u001b[38;5;7mfinal_answer\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;7mcode\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[0m\n",
      "\u001b[33;1m====\u001b[0m\n",
      "\u001b[33;1mPrint outputs:\u001b[0m\n",
      "\u001b[32;20m[0, 1, 2]\n",
      "0\n",
      "1\n",
      "2\n",
      "\u001b[0m\n",
      "\u001b[33;1m>>> Final answer:\u001b[0m\n",
      "\u001b[32;20m\n",
      "list=[0, 1, 2]\n",
      "\n",
      "for i in range(4):\n",
      "    print(list(i))\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from transformers import ReactCodeAgent\n",
    "\n",
    "agent = ReactCodeAgent(tools=[])\n",
    "\n",
    "code = \"\"\"\n",
    "list=[0, 1, 2]\n",
    "\n",
    "for i in range(4):\n",
    "    print(list(i))\n",
    "\"\"\"\n",
    "\n",
    "final_answer = agent.run(\n",
    "    \"I have some code that creates a bug: please debug it and return the final code\",\n",
    "    code=code,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ­£å¦‚ä½ æ‰€çœ‹åˆ°çš„ï¼Œæ™ºèƒ½ä½“å°è¯•äº†ç»™å®šçš„ä»£ç ï¼Œé‡åˆ°é”™è¯¯ï¼Œåˆ†æé”™è¯¯ï¼Œçº æ­£ä»£ç ï¼Œå¹¶åœ¨éªŒè¯ä»£ç å¯ä»¥æ­£å¸¸å·¥ä½œåè¿”å›å®ƒï¼\n",
    "\n",
    "æœ€ç»ˆçš„ä»£ç æ˜¯çº æ­£åçš„ä»£ç ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "list=[0, 1, 2]\n",
      "\n",
      "for i in range(4):\n",
      "    print(list(i))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. åˆ›å»ºä½ è‡ªå·±çš„ LLM å¼•æ“ï¼ˆOpenAIï¼‰\n",
    "\n",
    "è®¾ç½®ä½ è‡ªå·±çš„ LLM å¼•æ“çœŸçš„éå¸¸ç®€å•ï¼š\n",
    "å®ƒåªéœ€è¦ä¸€ä¸ªå…·æœ‰ä»¥ä¸‹æ ‡å‡†çš„`__call__`æ–¹æ³•ï¼š\n",
    "1. æ¥å—[ChatML æ ¼å¼](https://huggingface.co/docs/transformers/main/en/chat_templating#introduction)çš„æ¶ˆæ¯åˆ—è¡¨ä½œä¸ºè¾“å…¥å¹¶è¾“å‡ºç­”æ¡ˆã€‚\n",
    "2. æ¥å—ä¸€ä¸ª `stop_sequences` å‚æ•°ï¼Œä»¥ä¼ é€’ç”Ÿæˆåœæ­¢çš„åºåˆ—ã€‚\n",
    "3. æ ¹æ®ä½ çš„ LLM æ¥å—å“ªç§ç±»å‹çš„æ¶ˆæ¯è§’è‰²ï¼Œä½ å¯èƒ½è¿˜éœ€è¦è½¬æ¢ä¸€äº›æ¶ˆæ¯è§’è‰²ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m======== New task ========\u001b[0m\n",
      "\u001b[37;1mI have some code that creates a bug: please debug it and return the final code\n",
      "You have been provided with these initial arguments: {'code': '\\nlist=[0, 1, 2]\\n\\nfor i in range(4):\\n    print(list(i))\\n'}.\u001b[0m\n",
      "\u001b[33;1m==== Agent is executing the code below:\u001b[0m\n",
      "\u001b[0m\u001b[38;5;7mmy_list\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;109;01m=\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;7m[\u001b[39m\u001b[38;5;139m0\u001b[39m\u001b[38;5;7m,\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;139m1\u001b[39m\u001b[38;5;7m,\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;139m2\u001b[39m\u001b[38;5;7m]\u001b[39m\u001b[38;5;7m  \u001b[39m\u001b[38;5;60;03m# Renamed the list to avoid using the built-in name\u001b[39;00m\n",
      "\n",
      "\u001b[38;5;109;01mfor\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;7mi\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;109;01min\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;109mrange\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;109mlen\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;7mmy_list\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[38;5;7m:\u001b[39m\u001b[38;5;7m  \u001b[39m\u001b[38;5;60;03m# Changed the range to be within the length of the list\u001b[39;00m\n",
      "\u001b[38;5;7m    \u001b[39m\u001b[38;5;109mprint\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;7mmy_list\u001b[39m\u001b[38;5;7m[\u001b[39m\u001b[38;5;7mi\u001b[39m\u001b[38;5;7m]\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[38;5;7m  \u001b[39m\u001b[38;5;60;03m# Corrected the list access syntax\u001b[39;00m\u001b[0m\n",
      "\u001b[33;1m====\u001b[0m\n",
      "\u001b[33;1mPrint outputs:\u001b[0m\n",
      "\u001b[32;20m0\n",
      "1\n",
      "2\n",
      "\u001b[0m\n",
      "\u001b[33;1m==== Agent is executing the code below:\u001b[0m\n",
      "\u001b[0m\u001b[38;5;7mmy_list\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;109;01m=\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;7m[\u001b[39m\u001b[38;5;139m0\u001b[39m\u001b[38;5;7m,\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;139m1\u001b[39m\u001b[38;5;7m,\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;139m2\u001b[39m\u001b[38;5;7m]\u001b[39m\u001b[38;5;7m  \u001b[39m\u001b[38;5;60;03m# Renamed the list to avoid using the built-in name\u001b[39;00m\n",
      "\n",
      "\u001b[38;5;109;01mfor\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;7mi\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;109;01min\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;109mrange\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;109mlen\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;7mmy_list\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[38;5;7m:\u001b[39m\u001b[38;5;7m  \u001b[39m\u001b[38;5;60;03m# Changed the range to be within the length of the list\u001b[39;00m\n",
      "\u001b[38;5;7m    \u001b[39m\u001b[38;5;109mprint\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;7mmy_list\u001b[39m\u001b[38;5;7m[\u001b[39m\u001b[38;5;7mi\u001b[39m\u001b[38;5;7m]\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[38;5;7m  \u001b[39m\u001b[38;5;60;03m# Corrected the list access syntax\u001b[39;00m\u001b[0m\n",
      "\u001b[33;1m====\u001b[0m\n",
      "\u001b[33;1mPrint outputs:\u001b[0m\n",
      "\u001b[32;20m0\n",
      "1\n",
      "2\n",
      "\u001b[0m\n",
      "\u001b[33;1m==== Agent is executing the code below:\u001b[0m\n",
      "\u001b[0m\u001b[38;5;7mcorrected_code\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;109;01m=\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;144m'''\u001b[39m\n",
      "\u001b[38;5;144mmy_list = [0, 1, 2]  # Renamed the list to avoid using the built-in name\u001b[39m\n",
      "\n",
      "\u001b[38;5;144mfor i in range(len(my_list)):  # Changed the range to be within the length of the list\u001b[39m\n",
      "\u001b[38;5;144m    print(my_list[i])  # Corrected the list access syntax\u001b[39m\n",
      "\u001b[38;5;144m'''\u001b[39m\n",
      "\n",
      "\u001b[38;5;7mfinal_answer\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;7manswer\u001b[39m\u001b[38;5;109;01m=\u001b[39;00m\u001b[38;5;7mcorrected_code\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[0m\n",
      "\u001b[33;1m====\u001b[0m\n",
      "\u001b[33;1mPrint outputs:\u001b[0m\n",
      "\u001b[32;20m\u001b[0m\n",
      "\u001b[33;1m>>> Final answer:\u001b[0m\n",
      "\u001b[32;20m\n",
      "my_list = [0, 1, 2]  # Renamed the list to avoid using the built-in name\n",
      "\n",
      "for i in range(len(my_list)):  # Changed the range to be within the length of the list\n",
      "    print(my_list[i])  # Corrected the list access syntax\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from transformers.agents.llm_engine import MessageRole, get_clean_message_list\n",
    "\n",
    "openai_role_conversions = {\n",
    "    MessageRole.TOOL_RESPONSE: \"user\",\n",
    "}\n",
    "\n",
    "\n",
    "class OpenAIEngine:\n",
    "    def __init__(self, model_name=\"gpt-4o-2024-05-13\"):\n",
    "        self.model_name = model_name\n",
    "        self.client = OpenAI(\n",
    "            api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        )\n",
    "\n",
    "    def __call__(self, messages, stop_sequences=[]):\n",
    "        # Get clean message list\n",
    "        messages = get_clean_message_list(\n",
    "            messages, role_conversions=openai_role_conversions\n",
    "        )\n",
    "\n",
    "        # Get LLM output\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=messages,\n",
    "            stop=stop_sequences,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "\n",
    "openai_engine = OpenAIEngine()\n",
    "agent = ReactCodeAgent(llm_engine=openai_engine, tools=[])\n",
    "\n",
    "code = \"\"\"\n",
    "list=[0, 1, 2]\n",
    "\n",
    "for i in range(4):\n",
    "    print(list(i))\n",
    "\"\"\"\n",
    "\n",
    "final_answer = agent.run(\n",
    "    \"I have some code that creates a bug: please debug it and return the final code\",\n",
    "    code=code,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "my_list = [0, 1, 2]  # Renamed the list to avoid using the built-in name\n",
      "\n",
      "for i in range(len(my_list)):  # Changed the range to be within the length of the list\n",
      "    print(my_list[i])  # Corrected the list access syntax\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â¡ï¸ ç»“è®º\n",
    "\n",
    "ä¸Šè¿°ç”¨ä¾‹åº”è¯¥è®©ä½ å¯¹æˆ‘ä»¬æ™ºèƒ½ä½“æ¡†æ¶çš„å¯èƒ½æ€§æœ‰äº†åˆæ­¥äº†è§£ï¼\n",
    "\n",
    "æƒ³è¦äº†è§£æ›´å¤šé«˜çº§ç”¨æ³•ï¼Œè¯·é˜…è¯»[æ–‡æ¡£](https://huggingface.co/docs/transformers/en/transformers_agents)ï¼Œ ä»¥åŠ[æ­¤å®éªŒ](https://github.com/aymeric-roucher/agent_reasoning_benchmark/blob/main/benchmark_gaia.ipynb)ï¼Œå®ƒè®©æˆ‘ä»¬èƒ½å¤ŸåŸºäº Llama-3-70B æ„å»ºè‡ªå·±çš„æ™ºèƒ½ä½“ï¼Œå¹¶åœ¨éå¸¸å›°éš¾çš„[GAIA æ’è¡Œæ¦œ](https://huggingface.co/spaces/gaia-benchmark/leaderboard)ä¸Šå‡»è´¥è®¸å¤š GPT-4 æ™ºèƒ½ä½“ï¼\n",
    "\n",
    "æ¬¢è¿æ‰€æœ‰åé¦ˆï¼Œè¿™å°†å¸®åŠ©æˆ‘ä»¬æ”¹è¿›æ¡†æ¶ï¼ ğŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test2",
   "language": "python",
   "name": "test2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
