{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ä½¿ç”¨ Transformers Agents æž„å»ºå…·æœ‰å·¥å…·è°ƒç”¨è¶…èƒ½åŠ›çš„æ™ºèƒ½ä½“ ðŸ¦¸\n",
    "\n",
    "_ä½œè€…: [Aymeric Roucher](https://huggingface.co/m-ric)_\n",
    "\n",
    "\n",
    "è¿™ä¸ª notebook å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ [**Transformers Agents**](https://huggingface.co/docs/transformers/en/agents) æ¥æž„å»ºå‡ºè‰²çš„**æ™ºèƒ½ä½“**ï¼\n",
    "\n",
    "ä»€ä¹ˆæ˜¯**æ™ºèƒ½ä½“**ï¼Ÿæ™ºèƒ½ä½“æ˜¯ç”±å¤§åž‹è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰é©±åŠ¨çš„ç³»ç»Ÿï¼Œå®ƒä»¬ä½¿å¾— LLMï¼ˆé€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æç¤ºå’Œè¾“å‡ºè§£æžï¼‰èƒ½å¤Ÿä½¿ç”¨ç‰¹å®šçš„*å·¥å…·*æ¥è§£å†³é—®é¢˜ã€‚\n",
    "\n",
    "è¿™äº›*å·¥å…·*åŸºæœ¬ä¸Šæ˜¯ LLM è‡ªèº«æ— æ³•å¾ˆå¥½æ‰§è¡Œçš„åŠŸèƒ½ï¼šä¾‹å¦‚ï¼Œå¯¹äºŽåƒ [Llama-3-70B](https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct) è¿™æ ·çš„æ–‡æœ¬ç”Ÿæˆ LLMï¼Œè¿™å¯èƒ½æ˜¯ä¸€ä¸ªå›¾åƒç”Ÿæˆå·¥å…·ã€ç½‘ç»œæœç´¢å·¥å…·ã€è®¡ç®—å™¨...\n",
    "\n",
    "ä»€ä¹ˆæ˜¯ **Transformers Agents** ï¼Ÿå®ƒæ˜¯æˆ‘ä»¬ `transformers` åº“çš„ä¸€ä¸ªæ‰©å±•ï¼Œæä¾›äº†æž„å»ºè‡ªå·±çš„æ™ºèƒ½ä½“çš„æž„å»ºå—ï¼åœ¨[æ–‡æ¡£](https://huggingface.co/docs/transformers/en/agents)ä¸­äº†è§£æ›´å¤šä¿¡æ¯ã€‚\n",
    "\n",
    "è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•ä½¿ç”¨å®ƒï¼Œä»¥åŠå®ƒèƒ½è§£å†³å“ªäº›ç”¨ä¾‹ã€‚\n",
    "\n",
    "æˆ‘ä»¬ä»Žæºä»£ç å®‰è£… transformers agents ï¼Œä½ å¯ä»¥ä½¿ç”¨ `pip install transformers[agents]` è½»æ¾å®‰è£…ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: smolagents in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (1.0.0)\n",
      "Requirement already satisfied: torch in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from smolagents) (2.3.0)\n",
      "Requirement already satisfied: torchaudio in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from smolagents) (2.3.0)\n",
      "Requirement already satisfied: torchvision in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from smolagents) (0.18.0)\n",
      "Requirement already satisfied: transformers>=4.0.0 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from smolagents) (4.47.1)\n",
      "Requirement already satisfied: requests>=2.32.3 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from smolagents) (2.32.3)\n",
      "Requirement already satisfied: rich>=13.9.4 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from smolagents) (13.9.4)\n",
      "Requirement already satisfied: pandas>=2.2.3 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from smolagents) (2.2.3)\n",
      "Requirement already satisfied: jinja2>=3.1.4 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from smolagents) (3.1.4)\n",
      "Requirement already satisfied: pillow>=11.0.0 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from smolagents) (11.1.0)\n",
      "Requirement already satisfied: markdownify>=0.14.1 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from smolagents) (0.14.1)\n",
      "Requirement already satisfied: gradio>=5.8.0 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from smolagents) (5.9.1)\n",
      "Requirement already satisfied: duckduckgo-search>=6.3.7 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from smolagents) (7.2.0)\n",
      "Requirement already satisfied: python-dotenv>=1.0.1 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from smolagents) (1.0.1)\n",
      "Requirement already satisfied: e2b-code-interpreter>=1.0.3 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from smolagents) (1.0.3)\n",
      "Requirement already satisfied: litellm>=1.55.10 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from smolagents) (1.57.0)\n",
      "Requirement already satisfied: click>=8.1.7 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from duckduckgo-search>=6.3.7->smolagents) (8.1.7)\n",
      "Requirement already satisfied: primp>=0.9.3 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from duckduckgo-search>=6.3.7->smolagents) (0.9.3)\n",
      "Requirement already satisfied: lxml>=5.3.0 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from duckduckgo-search>=6.3.7->smolagents) (5.3.0)\n",
      "Requirement already satisfied: attrs>=21.3.0 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from e2b-code-interpreter>=1.0.3->smolagents) (23.2.0)\n",
      "Requirement already satisfied: e2b<2.0.0,>=1.0.4 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from e2b-code-interpreter>=1.0.3->smolagents) (1.0.5)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.20.0 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from e2b-code-interpreter>=1.0.3->smolagents) (0.27.2)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from gradio>=5.8.0->smolagents) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from gradio>=5.8.0->smolagents) (3.7.1)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from gradio>=5.8.0->smolagents) (0.115.6)\n",
      "Requirement already satisfied: ffmpy in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from gradio>=5.8.0->smolagents) (0.4.0)\n",
      "Requirement already satisfied: gradio-client==1.5.2 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from gradio>=5.8.0->smolagents) (1.5.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.1 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from gradio>=5.8.0->smolagents) (0.27.1)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from gradio>=5.8.0->smolagents) (2.1.5)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from gradio>=5.8.0->smolagents) (2.1.3)\n",
      "Requirement already satisfied: orjson~=3.0 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from gradio>=5.8.0->smolagents) (3.10.11)\n",
      "Requirement already satisfied: packaging in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from gradio>=5.8.0->smolagents) (24.2)\n",
      "Requirement already satisfied: pydantic>=2.0 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from gradio>=5.8.0->smolagents) (2.9.2)\n",
      "Requirement already satisfied: pydub in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from gradio>=5.8.0->smolagents) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from gradio>=5.8.0->smolagents) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from gradio>=5.8.0->smolagents) (6.0.1)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from gradio>=5.8.0->smolagents) (0.3.4)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from gradio>=5.8.0->smolagents) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from gradio>=5.8.0->smolagents) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from gradio>=5.8.0->smolagents) (0.41.3)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from gradio>=5.8.0->smolagents) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from gradio>=5.8.0->smolagents) (0.12.5)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from gradio>=5.8.0->smolagents) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from gradio>=5.8.0->smolagents) (0.30.6)\n",
      "Requirement already satisfied: fsspec in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from gradio-client==1.5.2->gradio>=5.8.0->smolagents) (2024.3.1)\n",
      "Requirement already satisfied: websockets<15.0,>=10.0 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from gradio-client==1.5.2->gradio>=5.8.0->smolagents) (12.0)\n",
      "Requirement already satisfied: aiohttp in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from litellm>=1.55.10->smolagents) (3.9.3)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from litellm>=1.55.10->smolagents) (8.5.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from litellm>=1.55.10->smolagents) (4.22.0)\n",
      "Requirement already satisfied: openai>=1.55.3 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from litellm>=1.55.10->smolagents) (1.59.3)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from litellm>=1.55.10->smolagents) (0.8.0)\n",
      "Requirement already satisfied: tokenizers in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from litellm>=1.55.10->smolagents) (0.21.0)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.9 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from markdownify>=0.14.1->smolagents) (4.12.3)\n",
      "Requirement already satisfied: six<2,>=1.15 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from markdownify>=0.14.1->smolagents) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from pandas>=2.2.3->smolagents) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from pandas>=2.2.3->smolagents) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from pandas>=2.2.3->smolagents) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from requests>=2.32.3->smolagents) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from requests>=2.32.3->smolagents) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from requests>=2.32.3->smolagents) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from requests>=2.32.3->smolagents) (2023.11.17)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from rich>=13.9.4->smolagents) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from rich>=13.9.4->smolagents) (2.18.0)\n",
      "Requirement already satisfied: filelock in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from transformers>=4.0.0->smolagents) (3.13.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from transformers>=4.0.0->smolagents) (2024.5.10)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from transformers>=4.0.0->smolagents) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from transformers>=4.0.0->smolagents) (4.66.1)\n",
      "Requirement already satisfied: sympy in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from torch->smolagents) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from torch->smolagents) (3.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from anyio<5.0,>=3.0->gradio>=5.8.0->smolagents) (1.3.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from beautifulsoup4<5,>=4.9->markdownify>=0.14.1->smolagents) (2.5)\n",
      "Requirement already satisfied: httpcore<2.0.0,>=1.0.5 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from e2b<2.0.0,>=1.0.4->e2b-code-interpreter>=1.0.3->smolagents) (1.0.7)\n",
      "Requirement already satisfied: protobuf<6.0.0,>=3.20.0 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from e2b<2.0.0,>=1.0.4->e2b-code-interpreter>=1.0.3->smolagents) (5.29.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from httpcore<2.0.0,>=1.0.5->e2b<2.0.0,>=1.0.4->e2b-code-interpreter>=1.0.3->smolagents) (0.14.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from importlib-metadata>=6.8.0->litellm>=1.55.10->smolagents) (3.21.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.55.10->smolagents) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.55.10->smolagents) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.55.10->smolagents) (0.18.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->smolagents) (0.1.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from openai>=1.55.3->litellm>=1.55.10->smolagents) (1.8.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from openai>=1.55.3->litellm>=1.55.10->smolagents) (0.7.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from pydantic>=2.0->gradio>=5.8.0->smolagents) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from pydantic>=2.0->gradio>=5.8.0->smolagents) (2.23.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from typer<1.0,>=0.12->gradio>=5.8.0->smolagents) (1.5.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from aiohttp->litellm>=1.55.10->smolagents) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from aiohttp->litellm>=1.55.10->smolagents) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from aiohttp->litellm>=1.55.10->smolagents) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from aiohttp->litellm>=1.55.10->smolagents) (1.9.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from sympy->torch->smolagents) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install smolagents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets huggingface_hub langchain sentence-transformers faiss-cpu serpapi google-search-results openai -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ðŸžï¸ å¤šæ¨¡æ€ + ðŸŒ ç½‘ç»œæµè§ˆåŠ©æ‰‹\n",
    "\n",
    "å¯¹äºŽè¿™ä¸ªç”¨ä¾‹ï¼Œæˆ‘ä»¬æƒ³è¦å±•ç¤ºä¸€ä¸ªèƒ½å¤Ÿæµè§ˆç½‘ç»œå¹¶èƒ½å¤Ÿç”Ÿæˆå›¾åƒçš„æ™ºèƒ½ä½“ã€‚\n",
    "\n",
    "ä¸ºäº†æž„å»ºå®ƒï¼Œæˆ‘ä»¬åªéœ€è¦å‡†å¤‡ä¸¤ä¸ªå·¥å…·ï¼šå›¾åƒç”Ÿæˆå’Œç½‘ç»œæœç´¢ã€‚\n",
    "- å¯¹äºŽå›¾åƒç”Ÿæˆï¼Œæˆ‘ä»¬ä»Ž Hub åŠ è½½ä¸€ä¸ªå·¥å…·ï¼Œè¯¥å·¥å…·ä½¿ç”¨ HF æŽ¨ç† APIï¼ˆæ— æœåŠ¡å™¨ï¼‰ä½¿ç”¨ Stable Diffusion ç”Ÿæˆå›¾åƒã€‚\n",
    "- å¯¹äºŽç½‘ç»œæœç´¢ï¼Œæˆ‘ä»¬åŠ è½½ä¸€ä¸ª LangChain å·¥å…·ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'HfApiModel' from 'transformers' (/Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tool, load_tool, CodeAgent, HfApiModel\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Import tool from Hub\u001b[39;00m\n\u001b[1;32m      4\u001b[0m image_generation_tool \u001b[38;5;241m=\u001b[39m load_tool(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm-ric/text-to-image\u001b[39m\u001b[38;5;124m\"\u001b[39m, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'HfApiModel' from 'transformers' (/Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages/transformers/__init__.py)"
     ]
    }
   ],
   "source": [
    "from transformers import Tool, load_tool, CodeAgent, HfApiModel\n",
    "\n",
    "# Import tool from Hub\n",
    "image_generation_tool = load_tool(\"m-ric/text-to-image\", trust_remote_code=True)\n",
    "\n",
    "# Import tool from LangChain\n",
    "from langchain.agents import load_tools\n",
    "\n",
    "search_tool = Tool.from_langchain(load_tools([\"serpapi\"])[0])\n",
    "\n",
    "\n",
    "model = HfApiModel(\"meta-llama/Llama-3.1-70B-Instruct\")\n",
    "# Initialize the agent with both tools\n",
    "agent = CodeAgent(\n",
    "    tools=[image_generation_tool, search_tool], model=model\n",
    ")\n",
    "\n",
    "# Run it!\n",
    "result = agent.run(\n",
    "    \"Generate me a photo of the car that James bond drove in the latest movie.\",\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of an Aston Martin DB5](https://huggingface.co/datasets/huggingface/cookbook-images/resolve/main/agents_db5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ðŸ“šðŸ’¬ å¸¦æœ‰è¿­ä»£æŸ¥è¯¢ä¼˜åŒ–å’Œæ¥æºé€‰æ‹©çš„ RAG\n",
    "å¿«é€Ÿå®šä¹‰ï¼šæ£€ç´¢å¢žå¼ºç”Ÿæˆï¼ˆRAGï¼‰æ˜¯ ___â€œä½¿ç”¨å¤§åž‹è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰æ¥å›žç­”ç”¨æˆ·æŸ¥è¯¢ï¼Œä½†åŸºäºŽä»ŽçŸ¥è¯†åº“æ£€ç´¢åˆ°çš„ä¿¡æ¯æ¥æž„å»ºç­”æ¡ˆâ€___ã€‚\n",
    "\n",
    "è¿™ç§æ–¹æ³•ç›¸æ¯”ä½¿ç”¨æ™®é€šæˆ–å¾®è°ƒçš„ LLM æœ‰è®¸å¤šä¼˜åŠ¿ï¼šåˆ—ä¸¾ä¸€äº›ï¼Œå®ƒå…è®¸å°†ç­”æ¡ˆå»ºç«‹åœ¨çœŸå®žäº‹å®žçš„åŸºç¡€ä¸Šå¹¶å‡å°‘è™šæž„ï¼Œå®ƒå…è®¸ä¸º LLM æä¾›ç‰¹å®šé¢†åŸŸçš„çŸ¥è¯†ï¼Œå¹¶ä¸”å®ƒå…è®¸å¯¹çŸ¥è¯†åº“ä¸­çš„ä¿¡æ¯è®¿é—®è¿›è¡Œç»†ç²’åº¦æŽ§åˆ¶ã€‚\n",
    "\n",
    "- çŽ°åœ¨å‡è®¾æˆ‘ä»¬æƒ³è¦æ‰§è¡Œ RAGï¼Œä½†å¢žåŠ äº†åŠ¨æ€ç”ŸæˆæŸäº›å‚æ•°çš„çº¦æŸã€‚ä¾‹å¦‚ï¼Œæ ¹æ®ç”¨æˆ·æŸ¥è¯¢ï¼Œæˆ‘ä»¬å¯èƒ½æƒ³è¦å°†æœç´¢é™åˆ¶åœ¨çŸ¥è¯†åº“çš„ç‰¹å®šå­é›†ï¼Œæˆ–è€…æˆ‘ä»¬å¯èƒ½æƒ³è¦è°ƒæ•´æ£€ç´¢åˆ°çš„æ–‡æ¡£æ•°é‡ã€‚éš¾ç‚¹åœ¨äºŽï¼š**å¦‚ä½•æ ¹æ®ç”¨æˆ·æŸ¥è¯¢åŠ¨æ€è°ƒæ•´è¿™äº›å‚æ•°ï¼Ÿ**\n",
    "\n",
    "- RAG çš„ä¸€ä¸ªå¸¸è§å¤±è´¥æ¡ˆä¾‹æ˜¯åŸºäºŽç”¨æˆ·æŸ¥è¯¢çš„æ£€ç´¢æ²¡æœ‰è¿”å›žä»»ä½•ç›¸å…³çš„æ”¯æŒæ–‡æ¡£ã€‚**æœ‰æ²¡æœ‰ä¸€ç§æ–¹æ³•ï¼Œåœ¨ä¹‹å‰çš„ç»“æžœä¸ç›¸å…³æ—¶ï¼Œé€šè¿‡ä¿®æ”¹æŸ¥è¯¢é‡æ–°è°ƒç”¨æ£€ç´¢å™¨æ¥è¿›è¡Œè¿­ä»£ï¼Ÿ**\n",
    "\n",
    "ðŸ”§ å¥½å§ï¼Œæˆ‘ä»¬å¯ä»¥ä»¥ç®€å•çš„æ–¹å¼è§£å†³ä¸Šè¿°é—®é¢˜ï¼šæˆ‘ä»¬å°†**è®©æˆ‘ä»¬çš„æ™ºèƒ½ä½“æŽ§åˆ¶æ£€ç´¢å™¨çš„å‚æ•°ï¼**\n",
    "\n",
    "âž¡ï¸ è®©æˆ‘ä»¬å±•ç¤ºå¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹ã€‚æˆ‘ä»¬é¦–å…ˆåŠ è½½ä¸€ä¸ªæˆ‘ä»¬æƒ³è¦æ‰§è¡Œ RAG çš„çŸ¥è¯†åº“ï¼šè¿™ä¸ªæ•°æ®é›†æ˜¯è®¸å¤š `huggingface` åŒ…çš„æ–‡æ¡£é¡µé¢æ±‡æ€»ï¼Œä»¥ markdown æ ¼å¼å­˜å‚¨ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aymeric/.pyenv/versions/3.12.0/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "knowledge_base = datasets.load_dataset(\"m-ric/huggingface_doc\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "çŽ°åœ¨æˆ‘ä»¬é€šè¿‡å¤„ç†æ•°æ®é›†å¹¶å°†å…¶å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“ä¸­æ¥å‡†å¤‡çŸ¥è¯†åº“ï¼Œä»¥ä¾¿æ£€ç´¢å™¨ä½¿ç”¨ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ LangChainï¼Œå› ä¸ºå®ƒå…·æœ‰ç”¨äºŽå‘é‡æ•°æ®åº“çš„ä¼˜ç§€å·¥å…·ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "source_docs = [\n",
    "    Document(page_content=doc[\"text\"], metadata={\"source\": doc[\"source\"].split(\"/\")[1]})\n",
    "    for doc in knowledge_base\n",
    "]\n",
    "\n",
    "docs_processed = RecursiveCharacterTextSplitter(chunk_size=500).split_documents(\n",
    "    source_docs\n",
    ")[:1000]\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"thenlper/gte-small\")\n",
    "vectordb = FAISS.from_documents(documents=docs_processed, embedding=embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "çŽ°åœ¨æˆ‘ä»¬å·²ç»å‡†å¤‡å¥½äº†æ•°æ®åº“ï¼Œè®©æˆ‘ä»¬æž„å»ºä¸€ä¸ªåŸºäºŽå®ƒå›žç­”ç”¨æˆ·æŸ¥è¯¢çš„ RAG ç³»ç»Ÿï¼\n",
    "\n",
    "æˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„ç³»ç»Ÿæ ¹æ®æŸ¥è¯¢åªä»Žæœ€ç›¸å…³çš„ä¿¡æ¯æ¥æºä¸­é€‰æ‹©ã€‚\n",
    "\n",
    "æˆ‘ä»¬çš„æ–‡æ¡£é¡µé¢æ¥è‡ªä»¥ä¸‹æ¥æºï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['evaluate', 'course', 'deep-rl-class', 'peft', 'hf-endpoints-documentation', 'blog', 'gradio', 'datasets', 'datasets-server', 'transformers', 'optimum', 'hub-docs', 'pytorch-image-models', 'diffusers']\n"
     ]
    }
   ],
   "source": [
    "all_sources = list(set([doc.metadata[\"source\"] for doc in docs_processed]))\n",
    "print(all_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from smolagents import Tool\n",
    "from langchain_core.vectorstores import VectorStore\n",
    "\n",
    "\n",
    "class RetrieverTool(Tool):\n",
    "    name = \"retriever\"\n",
    "    description = \"Retrieves some documents from the knowledge base that have the closest embeddings to the input query.\"\n",
    "    inputs = {\n",
    "        \"query\": {\n",
    "            \"type\": \"text\",\n",
    "            \"description\": \"The query to perform. This should be semantically close to your target documents. Use the affirmative form rather than a question.\",\n",
    "        },\n",
    "        \"source\": {\"type\": \"text\", \"description\": \"\"},\n",
    "        \"number_of_documents\": {\n",
    "            \"type\": \"text\",\n",
    "            \"description\": \"the number of documents to retrieve. Stay under 10 to avoid drowning in docs\",\n",
    "        },\n",
    "    }\n",
    "    output_type = \"text\"\n",
    "\n",
    "    def __init__(self, vectordb: VectorStore, all_sources: str, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.vectordb = vectordb\n",
    "        self.inputs[\"source\"][\n",
    "            \"description\"\n",
    "        ] = f\"The source of the documents to search, as a str representation of a list. Possible values in the list are: {all_sources}. If this argument is not provided, all sources will be searched.\"\n",
    "\n",
    "    def forward(self, query: str, source: str = None, number_of_documents=7) -> str:\n",
    "        assert isinstance(query, str), \"Your search query must be a string\"\n",
    "        number_of_documents = int(number_of_documents)\n",
    "\n",
    "        if source:\n",
    "            if isinstance(source, str) and \"[\" not in str(\n",
    "                source\n",
    "            ):  # if the source is not representing a list\n",
    "                source = [source]\n",
    "            source = json.loads(str(source).replace(\"'\", '\"'))\n",
    "\n",
    "        docs = self.vectordb.similarity_search(\n",
    "            query,\n",
    "            filter=({\"source\": source} if source else None),\n",
    "            k=number_of_documents,\n",
    "        )\n",
    "\n",
    "        if len(docs) == 0:\n",
    "            return \"No documents found with this filtering. Try removing the source filter.\"\n",
    "        return \"Retrieved documents:\\n\\n\" + \"\\n===Document===\\n\".join(\n",
    "            [doc.page_content for doc in docs]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¯é€‰ï¼šå°†ä½ çš„æ£€ç´¢å™¨å·¥å…·åˆ†äº«åˆ° Hub\n",
    "\n",
    "è¦å°†ä½ çš„å·¥å…·åˆ†äº«åˆ° Hubï¼Œé¦–å…ˆå°†æ£€ç´¢å™¨å·¥å…·å®šä¹‰å•å…ƒæ ¼ä¸­çš„ä»£ç å¤åˆ¶ç²˜è´´åˆ°ä¸€ä¸ªåä¸ºä¾‹å¦‚ `retriever.py` çš„æ–°æ–‡ä»¶ä¸­ã€‚\n",
    "\n",
    "å½“å·¥å…·ä»Žå•ç‹¬çš„æ–‡ä»¶åŠ è½½åŽï¼Œä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç å°†å…¶æŽ¨é€åˆ° Hubï¼ˆç¡®ä¿ä½¿ç”¨å…·æœ‰`å†™å…¥`è®¿é—®æƒé™çš„ token ç™»å½•ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share_to_hub = False\n",
    "\n",
    "if share_to_hub:\n",
    "    from huggingface_hub import login\n",
    "    from retriever import RetrieverTool\n",
    "\n",
    "    login(\"your_token\")\n",
    "\n",
    "    tool = RetrieverTool(vectordb, all_sources)\n",
    "\n",
    "    tool.push_to_hub(repo_id=\"m-ric/retriever-tool\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è¿è¡Œæ™ºèƒ½ä½“!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/spaces/m-ric/retriever-tool:\n",
      "- retriever.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "\u001b[33;1m======== New task ========\u001b[0m\n",
      "\u001b[37;1mPlease show me a LORA finetuning script\u001b[0m\n",
      "\u001b[33;1mCalling tool: 'retriever' with arguments: {'number_of_documents': '5', 'query': 'LORA finetuning script', 'source': \"['transformers', 'blog']\"}\u001b[0m\n",
      "\u001b[33;1mCalling tool: 'retriever' with arguments: {'number_of_documents': '5', 'query': 'LORA finetuning script'}\u001b[0m\n",
      "\u001b[33;1mCalling tool: 'retriever' with arguments: {'number_of_documents': '5', 'query': 'train_text_to_image_lora.py'}\u001b[0m\n",
      "\u001b[33;1mCalling tool: 'final_answer' with arguments: https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image_lora.py\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output:\n",
      "https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image_lora.py\n"
     ]
    }
   ],
   "source": [
    "from smolagents import HfModel, ToolCallingAgent, load_tool\n",
    "\n",
    "model = HfModel(\"meta-llama/Meta-Llama-3-70B-Instruct\")\n",
    "\n",
    "retriever_tool = load_tool(\n",
    "    \"m-ric/retriever-tool\", vectordb=vectordb, all_sources=all_sources\n",
    ")\n",
    "agent = ToolCallingAgent(tools=[retriever_tool], model=model, verbose=0)\n",
    "\n",
    "agent_output = agent.run(\"Please show me a LORA finetuning script\")\n",
    "\n",
    "print(\"Final output:\")\n",
    "print(agent_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿé¦–å…ˆï¼Œæ™ºèƒ½ä½“å¯åŠ¨äº†æ£€ç´¢å™¨ï¼Œå¹¶è€ƒè™‘äº†ç‰¹å®šçš„æ¥æºï¼ˆ`['transformers', 'blog']`ï¼‰ã€‚\n",
    "\n",
    "ä½†æ˜¯è¿™æ¬¡æ£€ç´¢æ²¡æœ‰äº§ç”Ÿè¶³å¤Ÿçš„ç»“æžœ â‡’ æ²¡å…³ç³»ï¼æ™ºèƒ½ä½“å¯ä»¥è¿­ä»£ä¹‹å‰çš„ç»“æžœï¼Œå› æ­¤å®ƒåªæ˜¯ç”¨ä¸é‚£ä¹ˆä¸¥æ ¼çš„æœç´¢å‚æ•°é‡æ–°è¿è¡Œäº†å®ƒçš„æ£€ç´¢ã€‚\n",
    "\n",
    "å› æ­¤ï¼Œç ”ç©¶æˆåŠŸäº†ï¼\n",
    "\n",
    "è¯·æ³¨æ„ï¼Œ**ä½¿ç”¨è°ƒç”¨æ£€ç´¢å™¨ä½œä¸ºå·¥å…·å¹¶å¯ä»¥åŠ¨æ€ä¿®æ”¹æŸ¥è¯¢å’Œå…¶ä»–æ£€ç´¢å‚æ•°çš„ LLM æ™ºèƒ½ä½“**æ˜¯ RAG çš„**æ›´ä¸€èˆ¬çš„è¡¨è¿°**ï¼Œè¿™ä¹Ÿæ¶µç›–äº†åƒè¿­ä»£æŸ¥è¯¢ä¼˜åŒ–è¿™æ ·çš„è®¸å¤š RAG æ”¹è¿›æŠ€æœ¯ã€‚\n",
    "\n",
    "## 3. ðŸ’» è°ƒè¯• Python ä»£ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m======== New task ========\u001b[0m\n",
      "\u001b[37;1mI have some code that creates a bug: please debug it and return the final code\n",
      "You have been provided with these initial arguments: {'code': '\\nlist=[0, 1, 2]\\n\\nfor i in range(4):\\n    print(list(i))\\n'}.\u001b[0m\n",
      "\u001b[33;1m==== Agent is executing the code below:\u001b[0m\n",
      "\u001b[0m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;109;01m=\u001b[39;00m\u001b[38;5;7m[\u001b[39m\u001b[38;5;139m0\u001b[39m\u001b[38;5;7m,\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;139m1\u001b[39m\u001b[38;5;7m,\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;139m2\u001b[39m\u001b[38;5;7m]\u001b[39m\n",
      "\u001b[38;5;109mprint\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;7m)\u001b[39m\n",
      "\u001b[38;5;109;01mfor\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;7mi\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;109;01min\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;109mrange\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;139m4\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[38;5;7m:\u001b[39m\n",
      "\u001b[38;5;7m    \u001b[39m\u001b[38;5;109mprint\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;7m[\u001b[39m\u001b[38;5;7mi\u001b[39m\u001b[38;5;7m]\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[0m\n",
      "\u001b[33;1m====\u001b[0m\n",
      "\u001b[31;20mFailed while trying to execute the code below:\n",
      "\u001b[0mlist=[0, 1, 2]\n",
      "print(list)\n",
      "for i in range(4):\n",
      "    print(list[i])\u001b[0m\n",
      "This failed due to the following error:\n",
      "list index out of range\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aymeric/Documents/Code/original_transformers/transformers/src/transformers/agents/agents.py\", line 823, in step\n",
      "    result = self.python_evaluator(code_action, available_tools, state=self.state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/aymeric/Documents/Code/original_transformers/transformers/src/transformers/agents/python_interpreter.py\", line 511, in evaluate_python_code\n",
      "    line_result = evaluate_ast(node, state, tools)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/aymeric/Documents/Code/original_transformers/transformers/src/transformers/agents/python_interpreter.py\", line 404, in evaluate_ast\n",
      "    return evaluate_for(expression, state, tools)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/aymeric/Documents/Code/original_transformers/transformers/src/transformers/agents/python_interpreter.py\", line 313, in evaluate_for\n",
      "    line_result = evaluate_ast(node, state, tools)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/aymeric/Documents/Code/original_transformers/transformers/src/transformers/agents/python_interpreter.py\", line 401, in evaluate_ast\n",
      "    return evaluate_ast(expression.value, state, tools)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/aymeric/Documents/Code/original_transformers/transformers/src/transformers/agents/python_interpreter.py\", line 365, in evaluate_ast\n",
      "    return evaluate_call(expression, state, tools)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/aymeric/Documents/Code/original_transformers/transformers/src/transformers/agents/python_interpreter.py\", line 215, in evaluate_call\n",
      "    args = [evaluate_ast(arg, state, tools) for arg in call.args]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/aymeric/Documents/Code/original_transformers/transformers/src/transformers/agents/python_interpreter.py\", line 423, in evaluate_ast\n",
      "    return evaluate_subscript(expression, state, tools)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/aymeric/Documents/Code/original_transformers/transformers/src/transformers/agents/python_interpreter.py\", line 236, in evaluate_subscript\n",
      "    return value[int(index)]\n",
      "           ~~~~~^^^^^^^^^^^^\n",
      "IndexError: list index out of range\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aymeric/Documents/Code/original_transformers/transformers/src/transformers/agents/agents.py\", line 623, in run\n",
      "    final_answer = self.step()\n",
      "                   ^^^^^^^^^^^\n",
      "  File \"/Users/aymeric/Documents/Code/original_transformers/transformers/src/transformers/agents/agents.py\", line 832, in step\n",
      "    raise AgentExecutionError(error_msg)\n",
      "transformers.agents.agents.AgentExecutionError: Failed while trying to execute the code below:\n",
      "\u001b[0mlist=[0, 1, 2]\n",
      "print(list)\n",
      "for i in range(4):\n",
      "    print(list[i])\u001b[0m\n",
      "This failed due to the following error:\n",
      "list index out of range\n",
      "\u001b[33;1m==== Agent is executing the code below:\u001b[0m\n",
      "\u001b[0m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;109;01m=\u001b[39;00m\u001b[38;5;7m[\u001b[39m\u001b[38;5;139m0\u001b[39m\u001b[38;5;7m,\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;139m1\u001b[39m\u001b[38;5;7m,\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;139m2\u001b[39m\u001b[38;5;7m]\u001b[39m\n",
      "\u001b[38;5;109mprint\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;7m)\u001b[39m\n",
      "\u001b[38;5;109;01mfor\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;7mi\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;109;01min\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;109mrange\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;139m3\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[38;5;7m:\u001b[39m\n",
      "\u001b[38;5;7m    \u001b[39m\u001b[38;5;109mprint\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;7m[\u001b[39m\u001b[38;5;7mi\u001b[39m\u001b[38;5;7m]\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[0m\n",
      "\u001b[33;1m====\u001b[0m\n",
      "\u001b[33;1mPrint outputs:\u001b[0m\n",
      "\u001b[32;20m[0, 1, 2]\n",
      "0\n",
      "1\n",
      "2\n",
      "\u001b[0m\n",
      "\u001b[33;1m==== Agent is executing the code below:\u001b[0m\n",
      "\u001b[0m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;109;01m=\u001b[39;00m\u001b[38;5;7m[\u001b[39m\u001b[38;5;139m0\u001b[39m\u001b[38;5;7m,\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;139m1\u001b[39m\u001b[38;5;7m,\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;139m2\u001b[39m\u001b[38;5;7m]\u001b[39m\n",
      "\u001b[38;5;109mprint\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;7m)\u001b[39m\n",
      "\u001b[38;5;109;01mfor\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;7mi\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;109;01min\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;109mrange\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;139m3\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[38;5;7m:\u001b[39m\n",
      "\u001b[38;5;7m    \u001b[39m\u001b[38;5;109mprint\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;7m[\u001b[39m\u001b[38;5;7mi\u001b[39m\u001b[38;5;7m]\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[0m\n",
      "\u001b[33;1m====\u001b[0m\n",
      "\u001b[33;1mPrint outputs:\u001b[0m\n",
      "\u001b[32;20m[0, 1, 2]\n",
      "0\n",
      "1\n",
      "2\n",
      "\u001b[0m\n",
      "\u001b[33;1m==== Agent is executing the code below:\u001b[0m\n",
      "\u001b[0m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;109;01m=\u001b[39;00m\u001b[38;5;7m[\u001b[39m\u001b[38;5;139m0\u001b[39m\u001b[38;5;7m,\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;139m1\u001b[39m\u001b[38;5;7m,\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;139m2\u001b[39m\u001b[38;5;7m]\u001b[39m\n",
      "\u001b[38;5;109mprint\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;7m)\u001b[39m\n",
      "\u001b[38;5;109;01mfor\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;7mi\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;109;01min\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;109mrange\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;109mlen\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[38;5;7m:\u001b[39m\n",
      "\u001b[38;5;7m    \u001b[39m\u001b[38;5;109mprint\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;7m[\u001b[39m\u001b[38;5;7mi\u001b[39m\u001b[38;5;7m]\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[0m\n",
      "\u001b[33;1m====\u001b[0m\n",
      "\u001b[33;1mPrint outputs:\u001b[0m\n",
      "\u001b[32;20m[0, 1, 2]\n",
      "0\n",
      "1\n",
      "2\n",
      "\u001b[0m\n",
      "\u001b[33;1m==== Agent is executing the code below:\u001b[0m\n",
      "\u001b[0m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;109;01m=\u001b[39;00m\u001b[38;5;7m[\u001b[39m\u001b[38;5;139m0\u001b[39m\u001b[38;5;7m,\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;139m1\u001b[39m\u001b[38;5;7m,\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;139m2\u001b[39m\u001b[38;5;7m]\u001b[39m\n",
      "\u001b[38;5;109mprint\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;7m)\u001b[39m\n",
      "\u001b[38;5;109;01mfor\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;7mi\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;109;01min\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;109mrange\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;139m3\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[38;5;7m:\u001b[39m\n",
      "\u001b[38;5;7m    \u001b[39m\u001b[38;5;109mprint\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;109mlist\u001b[39m\u001b[38;5;7m[\u001b[39m\u001b[38;5;7mi\u001b[39m\u001b[38;5;7m]\u001b[39m\u001b[38;5;7m)\u001b[39m\n",
      "\u001b[38;5;7mfinal_answer\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;7mcode\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[0m\n",
      "\u001b[33;1m====\u001b[0m\n",
      "\u001b[33;1mPrint outputs:\u001b[0m\n",
      "\u001b[32;20m[0, 1, 2]\n",
      "0\n",
      "1\n",
      "2\n",
      "\u001b[0m\n",
      "\u001b[33;1m>>> Final answer:\u001b[0m\n",
      "\u001b[32;20m\n",
      "list=[0, 1, 2]\n",
      "\n",
      "for i in range(4):\n",
      "    print(list(i))\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from smolagents import CodeAgent\n",
    "\n",
    "agent = CodeAgent(tools=[])\n",
    "\n",
    "code = \"\"\"\n",
    "list=[0, 1, 2]\n",
    "\n",
    "for i in range(4):\n",
    "    print(list(i))\n",
    "\"\"\"\n",
    "\n",
    "final_answer = agent.run(\n",
    "    \"I have some code that creates a bug: please debug it and return the final code\",\n",
    "    code=code,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ­£å¦‚ä½ æ‰€çœ‹åˆ°çš„ï¼Œæ™ºèƒ½ä½“å°è¯•äº†ç»™å®šçš„ä»£ç ï¼Œé‡åˆ°é”™è¯¯ï¼Œåˆ†æžé”™è¯¯ï¼Œçº æ­£ä»£ç ï¼Œå¹¶åœ¨éªŒè¯ä»£ç å¯ä»¥æ­£å¸¸å·¥ä½œåŽè¿”å›žå®ƒï¼\n",
    "\n",
    "æœ€ç»ˆçš„ä»£ç æ˜¯çº æ­£åŽçš„ä»£ç ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "list=[0, 1, 2]\n",
      "\n",
      "for i in range(4):\n",
      "    print(list(i))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. åˆ›å»ºä½ è‡ªå·±çš„ LLM å¼•æ“Žï¼ˆOpenAIï¼‰\n",
    "\n",
    "è®¾ç½®ä½ è‡ªå·±çš„ LLM å¼•æ“ŽçœŸçš„éžå¸¸ç®€å•ï¼š\n",
    "å®ƒåªéœ€è¦ä¸€ä¸ªå…·æœ‰ä»¥ä¸‹æ ‡å‡†çš„`__call__`æ–¹æ³•ï¼š\n",
    "1. æŽ¥å—[ChatML æ ¼å¼](https://huggingface.co/docs/transformers/main/en/chat_templating#introduction)çš„æ¶ˆæ¯åˆ—è¡¨ä½œä¸ºè¾“å…¥å¹¶è¾“å‡ºç­”æ¡ˆã€‚\n",
    "2. æŽ¥å—ä¸€ä¸ª `stop_sequences` å‚æ•°ï¼Œä»¥ä¼ é€’ç”Ÿæˆåœæ­¢çš„åºåˆ—ã€‚\n",
    "3. æ ¹æ®ä½ çš„ LLM æŽ¥å—å“ªç§ç±»åž‹çš„æ¶ˆæ¯è§’è‰²ï¼Œä½ å¯èƒ½è¿˜éœ€è¦è½¬æ¢ä¸€äº›æ¶ˆæ¯è§’è‰²ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m======== New task ========\u001b[0m\n",
      "\u001b[37;1mI have some code that creates a bug: please debug it and return the final code\n",
      "You have been provided with these initial arguments: {'code': '\\nlist=[0, 1, 2]\\n\\nfor i in range(4):\\n    print(list(i))\\n'}.\u001b[0m\n",
      "\u001b[33;1m==== Agent is executing the code below:\u001b[0m\n",
      "\u001b[0m\u001b[38;5;7mmy_list\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;109;01m=\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;7m[\u001b[39m\u001b[38;5;139m0\u001b[39m\u001b[38;5;7m,\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;139m1\u001b[39m\u001b[38;5;7m,\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;139m2\u001b[39m\u001b[38;5;7m]\u001b[39m\u001b[38;5;7m  \u001b[39m\u001b[38;5;60;03m# Renamed the list to avoid using the built-in name\u001b[39;00m\n",
      "\n",
      "\u001b[38;5;109;01mfor\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;7mi\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;109;01min\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;109mrange\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;109mlen\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;7mmy_list\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[38;5;7m:\u001b[39m\u001b[38;5;7m  \u001b[39m\u001b[38;5;60;03m# Changed the range to be within the length of the list\u001b[39;00m\n",
      "\u001b[38;5;7m    \u001b[39m\u001b[38;5;109mprint\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;7mmy_list\u001b[39m\u001b[38;5;7m[\u001b[39m\u001b[38;5;7mi\u001b[39m\u001b[38;5;7m]\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[38;5;7m  \u001b[39m\u001b[38;5;60;03m# Corrected the list access syntax\u001b[39;00m\u001b[0m\n",
      "\u001b[33;1m====\u001b[0m\n",
      "\u001b[33;1mPrint outputs:\u001b[0m\n",
      "\u001b[32;20m0\n",
      "1\n",
      "2\n",
      "\u001b[0m\n",
      "\u001b[33;1m==== Agent is executing the code below:\u001b[0m\n",
      "\u001b[0m\u001b[38;5;7mmy_list\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;109;01m=\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;7m[\u001b[39m\u001b[38;5;139m0\u001b[39m\u001b[38;5;7m,\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;139m1\u001b[39m\u001b[38;5;7m,\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;139m2\u001b[39m\u001b[38;5;7m]\u001b[39m\u001b[38;5;7m  \u001b[39m\u001b[38;5;60;03m# Renamed the list to avoid using the built-in name\u001b[39;00m\n",
      "\n",
      "\u001b[38;5;109;01mfor\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;7mi\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;109;01min\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;109mrange\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;109mlen\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;7mmy_list\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[38;5;7m:\u001b[39m\u001b[38;5;7m  \u001b[39m\u001b[38;5;60;03m# Changed the range to be within the length of the list\u001b[39;00m\n",
      "\u001b[38;5;7m    \u001b[39m\u001b[38;5;109mprint\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;7mmy_list\u001b[39m\u001b[38;5;7m[\u001b[39m\u001b[38;5;7mi\u001b[39m\u001b[38;5;7m]\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[38;5;7m  \u001b[39m\u001b[38;5;60;03m# Corrected the list access syntax\u001b[39;00m\u001b[0m\n",
      "\u001b[33;1m====\u001b[0m\n",
      "\u001b[33;1mPrint outputs:\u001b[0m\n",
      "\u001b[32;20m0\n",
      "1\n",
      "2\n",
      "\u001b[0m\n",
      "\u001b[33;1m==== Agent is executing the code below:\u001b[0m\n",
      "\u001b[0m\u001b[38;5;7mcorrected_code\u001b[39m\u001b[38;5;7m \u001b[39m\u001b[38;5;109;01m=\u001b[39;00m\u001b[38;5;7m \u001b[39m\u001b[38;5;144m'''\u001b[39m\n",
      "\u001b[38;5;144mmy_list = [0, 1, 2]  # Renamed the list to avoid using the built-in name\u001b[39m\n",
      "\n",
      "\u001b[38;5;144mfor i in range(len(my_list)):  # Changed the range to be within the length of the list\u001b[39m\n",
      "\u001b[38;5;144m    print(my_list[i])  # Corrected the list access syntax\u001b[39m\n",
      "\u001b[38;5;144m'''\u001b[39m\n",
      "\n",
      "\u001b[38;5;7mfinal_answer\u001b[39m\u001b[38;5;7m(\u001b[39m\u001b[38;5;7manswer\u001b[39m\u001b[38;5;109;01m=\u001b[39;00m\u001b[38;5;7mcorrected_code\u001b[39m\u001b[38;5;7m)\u001b[39m\u001b[0m\n",
      "\u001b[33;1m====\u001b[0m\n",
      "\u001b[33;1mPrint outputs:\u001b[0m\n",
      "\u001b[32;20m\u001b[0m\n",
      "\u001b[33;1m>>> Final answer:\u001b[0m\n",
      "\u001b[32;20m\n",
      "my_list = [0, 1, 2]  # Renamed the list to avoid using the built-in name\n",
      "\n",
      "for i in range(len(my_list)):  # Changed the range to be within the length of the list\n",
      "    print(my_list[i])  # Corrected the list access syntax\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from smolagents.model import MessageRole, get_clean_message_list\n",
    "\n",
    "openai_role_conversions = {\n",
    "    MessageRole.TOOL_RESPONSE: \"user\",\n",
    "}\n",
    "\n",
    "\n",
    "class OpenAIModel:\n",
    "    def __init__(self, model_name=\"gpt-4o-2024-05-13\"):\n",
    "        self.model_name = model_name\n",
    "        self.client = OpenAI(\n",
    "            api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        )\n",
    "\n",
    "    def __call__(self, messages, stop_sequences=[]):\n",
    "        # Get clean message list\n",
    "        messages = get_clean_message_list(\n",
    "            messages, role_conversions=openai_role_conversions\n",
    "        )\n",
    "\n",
    "        # Get LLM output\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=messages,\n",
    "            stop=stop_sequences,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "\n",
    "openai_engine = OpenAIModel()\n",
    "agent = CodeAgent(model=openai_engine, tools=[])\n",
    "\n",
    "code = \"\"\"\n",
    "list=[0, 1, 2]\n",
    "\n",
    "for i in range(4):\n",
    "    print(list(i))\n",
    "\"\"\"\n",
    "\n",
    "final_answer = agent.run(\n",
    "    \"I have some code that creates a bug: please debug it and return the final code\",\n",
    "    code=code,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "my_list = [0, 1, 2]  # Renamed the list to avoid using the built-in name\n",
      "\n",
      "for i in range(len(my_list)):  # Changed the range to be within the length of the list\n",
      "    print(my_list[i])  # Corrected the list access syntax\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âž¡ï¸ ç»“è®º\n",
    "\n",
    "ä¸Šè¿°ç”¨ä¾‹åº”è¯¥è®©ä½ å¯¹æˆ‘ä»¬æ™ºèƒ½ä½“æ¡†æž¶çš„å¯èƒ½æ€§æœ‰äº†åˆæ­¥äº†è§£ï¼\n",
    "\n",
    "æƒ³è¦äº†è§£æ›´å¤šé«˜çº§ç”¨æ³•ï¼Œè¯·é˜…è¯»[æ–‡æ¡£](https://huggingface.co/docs/transformers/en/transformers_agents)ï¼Œ ä»¥åŠ[æ­¤å®žéªŒ](https://github.com/aymeric-roucher/agent_reasoning_benchmark/blob/main/benchmark_gaia.ipynb)ï¼Œå®ƒè®©æˆ‘ä»¬èƒ½å¤ŸåŸºäºŽ Llama-3-70B æž„å»ºè‡ªå·±çš„æ™ºèƒ½ä½“ï¼Œå¹¶åœ¨éžå¸¸å›°éš¾çš„[GAIA æŽ’è¡Œæ¦œ](https://huggingface.co/spaces/gaia-benchmark/leaderboard)ä¸Šå‡»è´¥è®¸å¤š GPT-4 æ™ºèƒ½ä½“ï¼\n",
    "\n",
    "æ¬¢è¿Žæ‰€æœ‰åé¦ˆï¼Œè¿™å°†å¸®åŠ©æˆ‘ä»¬æ”¹è¿›æ¡†æž¶ï¼ ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test2",
   "language": "python",
   "name": "test2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
